@article{EJ1347524,
Title = {Formative Assessment Tasks as Indicators of Student Engagement for Predicting At-Risk Students in Programming Courses},
Author = {Veerasamy, Ashok Kumar and Laakso, Mikko-Jussi and D'Souza, Daryl},
Journal = {Informatics in Education},
Year = {2022},
Volume = {21},
Pages = {375-393},
DOI = {http://eric.ed.gov/?id=EJ1347524},
Abstract = {Previous studies have proposed many indicators to assess the effect of student engagement in learning and academic achievement but have not yet been clearly articulated. In addition, while student engagement tracking systems have been designed, they rely on the log data but not on performance data. This paper presents results of a non-machine learning model developed using ongoing formative assessment scores as indicators of student engagement. Visualisation of the classification tree results is employed as student engagement indicators for instructors to observe and intervene with students. The results of this study showed that ongoing assessment is related to student engagement and subsequent final programming exam performance and possible to identify students at-risk of failing the final exam. Finally, our study identified students impacted by the COVID-19 pandemic. These were students who attended the final programming exam in the semester 2019-2020 and who scored well in formative assessments. Based on these results we present a simple student engagement indicator and its potential application as a student progress monitor for early identification of students at risk.},
Keywords = {Formative Evaluation, Educational Indicators, Learner Engagement, At Risk Students, Prediction, Programming, Computer Science Education, Academic Achievement},
ISSN = { ISSN-1648-5831},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1351197,
Title = {Using Learner Analytics to Explore the Potential Contribution of Multimodal Formative Assessment to Academic Success in Higher Education},
Author = {Kohnke, Lucas and Foung, Dennis and Chen, Julia},
Journal = {SAGE Open},
Year = {2022},
Volume = {12},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1351197},
Abstract = {Blended learning pedagogical practices supported by learning management systems have become an important part of higher education curricula. In most cases, these blended curricula are evaluated through multimodal formative assessments. Although assessments can strongly affect student outcomes, research on the topic is limited. In this paper, we adopted a learning analytics approach to explore student engagement with formative assessments and the power of these assessments to predict student outcomes in an English for Academic Purposes courses in a Hong Kong university. The study retrieved the data logs from 7,815 students and used the data to analyze student engagement with the formative assessments. The results suggested that the students put effort into completing the assessments. The degree to which assessments predict learning outcomes depend on students' level of subject knowledge and their understanding of the relevance of the assessments. This study showed that learning analytics provided reliable evidence for understanding students' engagement and identifying at-risk students. Therefore, learning analytics research has the potential to inform pedagogical practice.},
Keywords = {Formative Evaluation, Higher Education, Outcomes of Education, Learning Analytics, Prediction, At Risk Students, Identification, English for Academic Purposes, Second Language Learning, Second Language Instruction, Foreign Countries, Blended Learning, Teaching Methods, Integrated Learning Systems, Learner Engagement, Undergraduate Students, Multimedia Materials, Evaluation Methods, Language Tests, Academic Achievement},
ISSN = { EISSN-2158-2440},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1385865,
Title = {i-Ntervene: Applying an Evidence-Based Learning Analytics Intervention to Support Computer Programming Instruction},
Author = {Utamachant, Piriya and Anutariya, Chutiporn and Pongnumkul, Suporn},
Journal = {Smart Learning Environments},
Year = {2023},
Volume = {10},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1385865},
Abstract = {Apart from good instructional design and delivery, effective intervention is another key to strengthen student academic performance. However, intervention has been recognized as a great challenge. Most instructors struggle to identify at-risk students, determine a proper intervention approach, trace and evaluate whether the intervention works. This process requires extensive effort and commitment, which is impractical especially for large classes with few instructors. This paper proposes a platform, namely "i-Ntervene," that integrates Learning Management System (LMS) automatic code grader, and learning analytics features which can empower systematic learning intervention for large programming classes. The platform supports instructor-pace courses on both Virtual Learning Environment (VLE) and traditional classroom setting. The platform iteratively assesses student engagement levels through learning activity gaps. It also analyzes subject understanding from programming question practices to identify at-risk students and suggests aspects of intervention based on their lagging in these areas. Students' post-intervention data are traced and evaluated quantitatively to determine effective intervention approaches. This evaluation method aligns with the evidence-based research design. The developed i-Ntervene prototype was tested on a Java programming course with 253 first-year university students during the COVID-19 pandemic in VLE. The result was satisfactory, as the instructors were able to perform and evaluate 12 interventions throughout a semester. For this experimental course, the platform revealed that the approach of sending extrinsic motivation emails had more impact in promoting learning behavior compared to other types of messages. It also showed that providing tutorial sessions was not an effective approach to improving students' subject understanding in complex algorithmic topics. i-Ntervene allows instructors to flexibly trial potential interventions to discover the optimal approach for their course settings which should boost student's learning outcomes in long term.},
Keywords = {Intervention, Learning Analytics, Learning Management Systems, Programming, Learner Engagement, Comprehension, At Risk Students, Evidence Based Practice, College Freshmen, Educational Technology, Electronic Learning, Student Motivation},
ISSN = { EISSN-2196-7091},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1362228,
Title = {Integration of Artificial Intelligence Performance Prediction and Learning Analytics to Improve Student Learning in Online Engineering Course},
Author = {Ouyang, Fan and Wu, Mian and Zheng, Luyi and Zhang, Liyin and Jiao, Pengcheng},
Journal = {International Journal of Educational Technology in Higher Education},
Year = {2023},
Volume = {20},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1362228},
Abstract = {As a cutting-edge field of artificial intelligence in education (AIEd) that depends on advanced computing technologies, AI performance prediction model is widely used to identify at-risk students that tend to fail, establish student-centered learning pathways, and optimize instructional design and development. A majority of the existing AI prediction models focus on the development and optimization of the accuracy of AI algorithms rather than applying AI models to provide student with in-time and continuous feedback and improve the students' learning quality. To fill this gap, this research integrated an AI performance prediction model with learning analytics approaches with a goal to improve student learning effects in a collaborative learning context. Quasi-experimental research was conducted in an online engineering course to examine the differences of students' collaborative learning effect with and without the support of the integrated approach. Results showed that the integrated approach increased student engagement, improved collaborative learning performances, and strengthen student satisfactions about learning. This research made contributions to proposing an integrated approach of AI models and learning analytics (LA) feedback and providing paradigmatic implications for future development of AI-driven learning analytics.},
Keywords = {Technology Integration, Artificial Intelligence, Performance, Prediction, Learning Analytics, Educational Improvement, Academic Achievement, Online Courses, Engineering Education, Cooperative Learning, Instructional Design, Student Centered Learning, At Risk Students, Student Satisfaction, Models},
ISSN = { EISSN-2365-9440},
Type = {Journal Articles, Reports - Research, Tests/Questionnaires},
Language = {English},
}


@article{ED624110,
Title = {Toward Better Grade Prediction via A2GP -- An Academic Achievement Inspired Predictive Model},
Author = {Qiu, Wei and Supraja, S. and Khong, Andy W. H.},
Journal = {International Educational Data Mining Society},
Year = {2022},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED624110},
Abstract = {Predicting student performance in an academic institution is important for detecting at-risk students and administering early-intervention strategies. We propose a new grade prediction model that considers three factors: temporal dynamics of prior courses across previous semesters, short-term performance consistency, and relative performance against peers. The proposed architecture comprises modules that incorporate the attention mechanism, a new short-term gated long short-term memory network, and a graph convolutional network to address limitations of existing works that fail to consider the above factors jointly. A weighted fusion layer is used to fuse learned representations of the above three modules--course importance, performance consistency, and relative performance. The aggregated representations are then used for grade prediction which, in turn, is used to classify at-risk students. Experiment results using three datasets obtained from over twenty thousand students across seventeen undergraduate courses show that the proposed model achieves low prediction errors and high F1 scores compared to existing models that predict grades and thereafter identifies at-risk students via a pre-defined threshold. [For the full proceedings, see ED623995.]},
Keywords = {Academic Achievement, Prediction, Grades (Scholastic), Models, At Risk Students, Identification, Undergraduate Students},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1239028,
Title = {Being More Human: Rooting Learning Analytics through "Re"sistance and "Re"connection with the Values of Higher Education},
Author = {Parkes, Sarah and Benkwitz, Adam and Bardy, Helen and Myler, Kerry and Peters, John},
Journal = {Higher Education Research and Development},
Year = {2020},
Volume = {39},
Pages = {113-126},
DOI = {http://eric.ed.gov/?id=EJ1239028},
Abstract = {Universities are now compelled to attend to metrics that (re)shape our conceptualisation of the student experience. New technologies such as learning analytics (LA) promise the ability to target personalised support to profiled 'at risk' students through mapping large-scale historic student engagement data such as attendance, library use, and virtual learning environment activity as well as demographic information and typical student outcomes. Yet serious ethical and implementation issues remain. Data-driven labelling of students as 'high risk', 'hard to reach' or 'vulnerable' creates conflict between promoting personal growth and human flourishing and treating people merely as data points. This article argues that universities must resist the assumption that numbers and algorithms alone can solve the 'problem' of student retention and performance; rather, LA work must be underpinned by a reconnection with the agreed values relating to the purpose of higher education, including democratic engagement, recognition of diverse and individual experience, and processes of becoming. Such a reconnection, this article contends, is possible when LA work is designed and implemented in genuine collaboration and partnership with students.},
Keywords = {Learning Analytics, Higher Education, Educational Objectives, Foreign Countries, School Holding Power, Academic Achievement, Values, Neoliberalism, Student Experience, College Students},
ISSN = { ISSN-0729-4360},
Type = {Journal Articles, Reports - Evaluative},
Language = {English},
}


@article{EJ1399343,
Title = {A Comprehensive Survey on Usage of Learning Analytics for Enhancing Learner's Performance in Learning Portals},
Author = {Shabnam Ara, S. J. and Tanuja, R. and Manjula, S. H. and Venugopal, K. R.},
Journal = {Journal of Educational Technology Systems},
Year = {2023},
Volume = {52},
Pages = {245-273},
DOI = {http://eric.ed.gov/?id=EJ1399343},
Abstract = {Learning analytics (LA) is considered a promising field of study as it's helping to improve learning and the context in which it occurs. A learner's performance can be defined as how well students are learning in terms of knowledge and skills development and can be analyzed based on students' outcomes and engagement in the course. We have consolidated the work carried out from 2011 to 2022 to improve learners' performance using LA, describe criteria that define learners' performance, discuss parameters that impact learners' performance, and how predictive models can be created to forecast learners' performance using these parameters. Results showed that the data collected from log files of the Learning Management System (LMS) had been used to get insights into the learner's performance in online platforms and LA could bring incredible benefits in the field of the education sector, such as improvement of learners' involvement with learning activities as well as learning outcomes, identification of students at risk, providing real-time feedback, and personalization of learning. Hence, we can say usage of LA significantly helps learners' performance improvement in learning portals. But we can get better results if we augment data from log files of LMS with the learner's personal data from his birth to the current moment, which is a bit challenging with respect to data collection i.e., huge and from multiple sources.},
Keywords = {Learning Analytics, Learning Management Systems, Academic Achievement, Prediction, Student Improvement, Learning Activities, At Risk Students, MOOCs, Intervention},
ISSN = { ISSN-0047-2395},
Type = {Journal Articles, Information Analyses, Reports - Research},
Language = {English},
}


@article{EJ1271891,
Title = {Identifying Factors of Students' Failure in Blended Courses by Analyzing Students' Engagement Data},
Author = {Georgakopoulos, Ioannis and Chalikias, Miltiadis and Zakopoulos, Vassilis and Kossieri, Evangelia},
Journal = {Education Sciences},
Year = {2020},
Volume = {10},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1271891},
Abstract = {Our modern era has brought about radical changes in the way courses are delivered and various teaching methods are being introduced to answer the purpose of meeting the modern learning challenges. On that account, the conventional way of teaching is giving place to a teaching method which combines conventional instructional strategies with contemporary learning trends. Thereby, a new course type has emerged, the blended course in the context of which online teaching and conventional instruction are efficiently mixed. This paper demonstrates a way to identify factors affecting students' critical performance in blended courses through a binary logistics regression analysis on students' engagement data. The binary logistics regression analysis has led to a risk model which identifies and prioritizes these factors in proportion to their contribution to the risk occurrence. The risk model is demonstrated in the context of two specific blended courses sharing the same learning design. Additionally, the outcome of the study has proved that factors related to the e-learning part have critically affected the students' performance in the respective blended courses.},
Keywords = {Academic Failure, Blended Learning, Learner Engagement, Student Participation, Learning Analytics, Integrated Learning Systems, Electronic Learning, Performance Factors, Models, At Risk Students, College Students, Grades (Scholastic), Identification, Foreign Countries, Academic Achievement},
ISSN = { EISSN-2227-7102},
Type = {Journal Articles, Reports - Research},
}
