@article{EJ1390059,
Title = {A Comparative Study on Student Performance Prediction Using Machine Learning},
Author = {Chen, Yawen and Zhai, Linbo},
Journal = {Education and Information Technologies},
Year = {2023},
Volume = {28},
Pages = {12039-12057},
DOI = {http://eric.ed.gov/?id=EJ1390059},
Abstract = {Accompanied with the development of storage and processing capacity of modern technology, educational data increases sharply. It is difficult for educational researchers to derive useful information from much educational data. Therefore, educational data mining techniques are important for the development of modern education field. Recently, researches have demonstrated that machine learning, as an important tool for data mining, has shown promising performance in educational applications, especially in student performance prediction. However, few studies comprehensively compare existing machine learning methods in educational data. Moreover, most current studies only focus on a single type of educational data for student performance prediction. In this paper, three different types of task-oriented educational data are employed to investigate the performance of machine learning methods in different application scenarios. Specifically, seven parameter-optimized machine learning methods are implemented to study multiple types of performance prediction, including binary and multi-classification prediction tasks. In the experimental section, four evaluation metrics and visualizations are presented for a comparative study of different methods on three tasks, and an elaborated discussion of the experimental results is provided. The experimental results demonstrate that Random Forest has achieved superior generality on all selected datasets. In addition, the performance of Decision Tree and Artificial Neural Network models on the selected datasets indicates that they are also potential candidates to solve student performance prediction tasks.},
Keywords = {Academic Achievement, Artificial Intelligence, Data Use, Information Retrieval, Student Characteristics},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1437774,
Title = {Integration of Collaborative Filtering into Naive Bayes Method to Enhance Student Performance Prediction},
Author = {Venera Nakhipova and Yerzhan Kerimbekov and Zhanat Umarova and Halil ibrahim Bulbul and Laura Suleimenova and Elvira Adylbekova},
Journal = {International Journal of Information and Communication Technology Education},
Year = {2024},
Volume = {20},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1437774},
Abstract = {This article introduces a novel method that integrates collaborative filtering into the naive Bayes model to enhance predicting student academic performance. The combined approach leverages collaborative user behavior analysis and probabilistic modeling, showing promising results in improved prediction precision. Collaborative Filtering explores user behavior patterns, while Naive Bayes employs Bayes' theorem for probabilistic data classification. Focused on predicting academic success, the integration incorporates collaborative patterns from student data for increased accuracy. The method considers similar students' performance and behavior for nuanced, personalized predictions. Starting with diverse data collection, including collaborative patterns among students, Collaborative Filtering identifies relationships and patterns among those with similar academic histories. These insights enrich the naive Bayes algorithm, creating a holistic approach for more accurate predictions, and contributing to ongoing machine learning initiatives in education.},
Keywords = {Academic Achievement, Prediction, Cooperation, Behavior, Models, Data Analysis, Algorithms, Artificial Intelligence},
ISSN = { ISSN-1550-1876},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1428731,
Title = {Enhancing Student Performance Prediction via Educational Data Mining on Academic Data},
Author = {Zareen Alamgir and Habiba Akram and Saira Karim and Aamir Wali},
Journal = {Informatics in Education},
Year = {2024},
Volume = {23},
Pages = {1-24},
DOI = {http://eric.ed.gov/?id=EJ1428731},
Abstract = {Educational data mining is widely deployed to extract valuable information and patterns from academic data. This research explores new features that can help predict the future performance of undergraduate students and identify at-risk students early on. It answers some crucial and intuitive questions that are not addressed by previous studies. Most of the existing research is conducted on data from 2-3 years in an absolute grading scheme. We examined the effects of historical academic data of 15 years on predictive modelling. Additionally, we explore the performance of undergraduate students in a relative grading scheme and examine the effects of grades in core courses and initial semesters on future performances. As a pilot study, we analyzed the academic performance of Computer Science university students. Many exciting discoveries were made; the duration and size of the historical data play a significant role in predicting future performance, mainly due to changes in curriculum, faculty, society, and evolving trends. Furthermore, predicting grades in advanced courses based on initial pre-requisite courses is challenging in a relative grading scheme, as students' performance depends not only on their efforts but also on their peers. In short, educational data mining can come to the rescue by uncovering valuable insights from academic data to predict future performances and identify the critical areas that need significant improvement.},
Keywords = {Data Analysis, Information Retrieval, Content Analysis, Information Technology, Pattern Recognition, Undergraduate Students, Academic Achievement, Grade Prediction, At Risk Students, Core Curriculum, Computer Science Education, Learning Analytics},
ISSN = { ISSN-1648-5831},
Type = {Journal Articles, Information Analyses},
Language = {English},
}


@article{EJ1341746,
Title = {Student Performance Prediction Model for Predicting Academic Achievement of High School Students},
Author = {Nuankaew, Pratya and Nuankaew, Wongpanya Sararat},
Journal = {European Journal of Educational Research},
Year = {2022},
Volume = {11},
Pages = {949-963},
DOI = {http://eric.ed.gov/?id=EJ1341746},
Abstract = {Modern technology is necessary and important for improving the quality of education. While machine learning algorithms to support students remain limited. Thus, it is necessary to inspire educational scholars and educational technologists. This research therefore has three main targets: to educate the holistic context of rural education management, to study the relationship of continuing education at the upper secondary level, and to construct an appropriate education program prediction model for high school students in a rural school. The data for research is the academic achievement data of 1,859 students from Manchasuksa School at Mancha Khiri District, Khon Kaen Province, Thailand, during the academic year 2015-2020. Research tools are separated into 2 sections. The first section is a basic statistical analysis step, it composes of frequency analysis, percentage analysis, mean analysis, and standard deviation analysis. Another section is the data mining analysis phase, which consists of discretization technique, XGBoost classification technique (Decision Tree, Gradient Boosted Trees, and Random Forest), confusion matrix performance analysis, and cross-validation performance analysis. At the end, the research results found that the reasonable distribution level of student achievement consisted of four clusters classified by academic achievement. All four clusters were modeled on predicting academic achievement for the next generation of students. In addition, there are four success models in this research. For future research, the researcher aims to develop an application to facilitate instruction for learners by integrating prediction models into the mobile application to promote the utilization of modern technology.},
Keywords = {Grade Prediction, Academic Achievement, High School Students, Rural Schools, Foreign Countries, Learning Analytics, Models, Lifelong Learning, Data Analysis},
ISSN = { EISSN-2165-8714},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1403552,
Title = {Students' Performance Prediction in Higher Education Using Multi-Agent Framework-Based Distributed Data Mining Approach: A Review},
Author = {M. Nazir and A. Noraziah and M. Rahmah},
Journal = {International Journal of Virtual and Personal Learning Environments},
Year = {2023},
Volume = {13},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1403552},
Abstract = {An effective educational program warrants the inclusion of an innovative construction that enhances the higher education efficacy in such a way that accelerates the achievement of desired results and reduces the risk of failures. Educational decision support system has currently been a hot topic in educational systems, facilitating the pupil result monitoring and evaluation to be performed during their development. In this literature survey, the authors have discussed the importance of multi-agent systems and comparative machine learning approaches in EDSS development. They explored the relationship between machine learning and multiagent intelligent systems in literature to conclude their effectiveness in student performance prediction paradigm. They used the PRISMA model for the literature review process. They finalized 18 articles published between 2014-2022 for the survey that match the research objectives.},
Keywords = {Data Analysis, Academic Achievement, Artificial Intelligence, Prediction, Undergraduate Students, Educational Research, Higher Education},
ISSN = { ISSN-1947-8518},
Type = {Journal Articles, Reports - Evaluative, Information Analyses},
Language = {English},
}


@article{EJ1363934,
Title = {Educational Data Mining to Predict Students' Academic Performance: A Survey Study},
Author = {Batool, Saba and Rashid, Junaid and Nisar, Muhammad Wasif and Kim, Jungeun and Kwon, Hyuk-Yoon and Hussain, Amir},
Journal = {Education and Information Technologies},
Year = {2023},
Volume = {28},
Pages = {905-971},
DOI = {http://eric.ed.gov/?id=EJ1363934},
Abstract = {Educational data mining is an emerging interdisciplinary research area involving both education and informatics. It has become an imperative research area due to many advantages that educational institutions can achieve. Along these lines, various data mining techniques have been used to improve learning outcomes by exploring large-scale data that come from educational settings. One of the main problems is predicting the future achievements of students before taking final exams, so we can proactively help students achieve better performance and prevent dropouts. Therefore, many efforts have been made to solve the problem of student performance prediction in the context of educational data mining. In this paper, we provide readers with a comprehensive understanding of student performance prediction and compare approximately 260 studies in the last 20 years with respect to i) major factors highly affecting student performance prediction, ii) kinds of data mining techniques including prediction and feature selection algorithms, and iii) frequently used data mining tools. The findings of the comprehensive analysis show that ANN and Random Forest are mostly used data mining algorithms, while WEKA is found as a trending tool for students' performance prediction. Students' academic records and demographic factors are the best attributes to predict performance. The study proves that irrelevant features in the dataset reduce the prediction results and increase model processing time. Therefore, almost half of the studies used feature selection techniques before building prediction models. This study attempts to provide useful and valuable information to researchers interested in advancing educational data mining. The study directs future researchers to achieve highly accurate prediction results in different scenarios using different available inputs or techniques. The study also helps institutions apply data mining techniques to predict and improve student outcomes by providing additional assistance on time.},
Keywords = {Academic Achievement, Prediction, Data Use, Information Retrieval, Pattern Recognition, Data Analysis, Research Reports, Student Characteristics},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research, Information Analyses},
Language = {English},
}


@article{EJ1342088,
Title = {Application of Educational Data Mining Approach for Student Academic Performance Prediction Using Progressive Temporal Data},
Author = {Trakunphutthirak, Ruangsak and Lee, Vincent C. S.},
Journal = {Journal of Educational Computing Research},
Year = {2022},
Volume = {60},
Pages = {742-776},
DOI = {http://eric.ed.gov/?id=EJ1342088},
Abstract = {Educators in higher education institutes often use statistical results obtained from their online Learning Management System (LMS) dataset, which has limitations, to evaluate student academic performance. This study differs from the current body of literature by including an additional dataset that advances the knowledge about factors affecting student academic performance. The key aims of this study are fourfold. First, is to fill the educational literature gap by applying machine learning techniques in educational data mining, making use of the Internet usage behaviour log files and LMS data. Second, LMS data and Internet usage log files were analysed with machine learning techniques for predicting at-risk-of-failure students, with greater explanation added by combining student demographic data. Third, the demographic features help to explain the prediction in understandable terms for educators. Fourth, the study used a range of Internet usage data, which were categorized according to type of usage data and type of web browsing data to increase prediction accuracy.},
Keywords = {Information Retrieval, Pattern Recognition, Data Analysis, Information Technology, Academic Achievement, Artificial Intelligence, Integrated Learning Systems, At Risk Students, Student Characteristics, Electronic Learning, Time on Task, Internet, Web Sites, Online Searching, Predictor Variables},
ISSN = { ISSN-0735-6331},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1360928,
Title = {A Data Mining Approach Using Machine Learning Algorithms For Early Detection of Low-Performing Students},
Author = {Khor, Ean Teng},
Journal = {International Journal of Information and Learning Technology},
Year = {2022},
Volume = {39},
Pages = {122-132},
DOI = {http://eric.ed.gov/?id=EJ1360928},
Abstract = {Purpose: The purpose of the study is to build predictive models for early detection of low-performing students and examine the factors that influence massive open online courses students' performance. Design/methodology/approach: For the first step, the author performed exploratory data analysis to analyze the dataset. The process was then followed by data pre-processing and feature engineering (Step 2). Next, the author conducted data modelling and prediction (Step 3). Finally, the performance of the developed models was evaluated (Step 4). Findings: The paper found that the decision trees algorithm outperformed other machine learning algorithms. The study also confirms the significant effect of the academic background and virtual learning environment (VLE) interactions feature categories to academic performance. The accuracy enhancement is 17.66% for decision trees classifier, 3.49% for logistic regression classifier and 4.89% for neural networks classifier. Based on the results of "CorrelationAttributeEval" technique with the use of a ranker search method, the author found that the "assessment_score" and "sum_click" features are more important among academic background and VLE interactions feature categories for the classification analysis in predicting students' academic performance. Originality/value: The work meets the originality requirement.},
Keywords = {Prediction, Low Achievement, Algorithms, Artificial Intelligence, Information Retrieval, Pattern Recognition, Data Analysis, MOOCs},
ISSN = { ISSN-2056-4880},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED615535,
Title = {Embedding Navigation Patterns for Student Performance Prediction},
Author = {Loginova, Ekaterina and Benoit, Dries F.},
Journal = {International Educational Data Mining Society},
Year = {2021},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED615535},
Abstract = {Predicting academic performance using trace data from learning management systems is a primary research topic in educational data mining. An important application is the identification of students at risk of failing the course or dropping out. However, most approaches utilise past grades, which are not always available and capture little of the student's learning strategy. The end-to-end models we implement predict whether a student will pass a course using only navigational patterns in a multimedia system, with the advantage of not requiring past grades. We experiment on a dataset containing coarse-grained action logs of more than 100,000 students participating in hundreds of short course. We propose two approaches to improve the performance: a novel encoding scheme for trace data, which reflects the course structure while remaining flexible enough to accommodate previously unseen courses, and unsupervised embeddings obtained with an autoencoder. To provide insight into model behaviour, we incorporate an attention mechanism. Clustering the vector representations of student behaviour produced by the proposed methods shows that distinct learning strategies specific to low- and high-achievers are extracted. [For the full proceedings, see ED615472.]},
Keywords = {Navigation (Information Systems), Academic Achievement, Grade Prediction, Integrated Learning Systems, Online Courses, Learning Strategies, Secondary School Students, Data Analysis},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1316702,
Title = {Fuzzy-Based Active Learning for Predicting Student Academic Performance Using autoML: A Step-Wise Approach},
Author = {Tsiakmaki, Maria and Kostopoulos, Georgios and Kotsiantis, Sotiris and Ragos, Omiros},
Journal = {Journal of Computing in Higher Education},
Year = {2021},
Volume = {33},
Pages = {635-667},
DOI = {http://eric.ed.gov/?id=EJ1316702},
Abstract = {Predicting students' learning outcomes is one of the main topics of interest in the area of Educational Data Mining and Learning Analytics. To this end, a plethora of machine learning methods has been successfully applied for solving a variety of predictive problems. However, it is of utmost importance for both educators and data scientists to develop accurate learning models at low cost. Fuzzy logic constitutes an appropriate approach for building models of high performance and transparency. In addition, active learning reduces both the time and cost of labeling effort, by exploiting a small set of labeled data along with a large set of unlabeled data in the most efficient way. In addition, choosing the proper method for a given problem formulation and configuring the optimal parameter setting is a demanding task, considering the high-dimensional input space and the complexity of machine learning algorithms. As such, exploring the potential of automated machine learning (autoML) strategies from the perspective of machine learning adeptness is important. In this context, the present study introduces a fuzzy-based active learning method for predicting students' academic performance which combines, in a modular way, autoML practices. A lot of experiments was carried out, revealing the efficiency of the proposed method for the accurate prediction of students at risk of failure. These insights may have the potential to support the learning experience and be useful the wider science of learning.},
Keywords = {Active Learning, Predictor Variables, Academic Achievement, Learning Analytics, Models, Automation, Artificial Intelligence, Efficiency, At Risk Students},
ISSN = { ISSN-1042-1726},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1356610,
Title = {Predicting Academic Performance Using Tree-Based Machine Learning Models: A Case Study of Bachelor Students in an Engineering Department in China},
Author = {Zhang, Wei and Wang, Yu and Wang, Suyu},
Journal = {Education and Information Technologies},
Year = {2022},
Volume = {27},
Pages = {13051-13066},
DOI = {http://eric.ed.gov/?id=EJ1356610},
Abstract = {Educational data mining (DEM) provides valuable educational information by applying data mining tools and techniques to analyze data at educational institutions. In this paper, tree-based machine learning algorithms are used to predict students' overall academic performance in their bachelor's program. The transcript data of the students in the same department in a Chinese university were collected. All the courses in the bachelor's program were then divided into six typical categories, and the mean GPAs of each category were taken as primary input features for prediction. Three tree-based machine learning models were established, i.e. decision tree (DT), Gradient boosting decision tree (GBDT) and random forest (RF). Results show that we can successfully identify more than 80% of the students at low-performance risk using the RF model at the end of the second semester, which is meaningful because the global quality of teaching and learning of the department can be improved by taking targeted measures in time according to the machine learning model. Feature importance and the structure of decision tree were also analyzed to extract knowledge that is valuable for both students and teachers. The results of this case study can be used as a reference for other engineering departments in China.},
Keywords = {Grade Prediction, Academic Achievement, Models, Artificial Intelligence, Engineering Education, Foreign Countries, College Students},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1314372,
Title = {A Systematic Literature Review of Student' Performance Prediction Using Machine Learning Techniques},
Author = {Albreiki, Balqis and Zaki, Nazar and Alashwal, Hany},
Journal = {Education Sciences},
Year = {2021},
Volume = {11},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1314372},
Abstract = {Educational Data Mining plays a critical role in advancing the learning environment by contributing state-of-the-art methods, techniques, and applications. The recent development provides valuable tools for understanding the student learning environment by exploring and utilizing educational data using machine learning and data mining techniques. Modern academic institutions operate in a highly competitive and complex environment. Analyzing performance, providing high-quality education, strategies for evaluating the students' performance, and future actions are among the prevailing challenges universities face. Student intervention plans must be implemented in these universities to overcome problems experienced by the students during their studies. In this systematic review, the relevant EDM literature related to identifying student dropouts and students at risk from 2009 to 2021 is reviewed. The review results indicated that various Machine Learning (ML) techniques are used to understand and overcome the underlying challenges; predicting students at risk and students drop out prediction. Moreover, most studies use two types of datasets: data from student colleges/university databases and online learning platforms. ML methods were confirmed to play essential roles in predicting students at risk and dropout rates, thus improving the students' performance.},
Keywords = {Literature Reviews, Grade Prediction, Artificial Intelligence, Educational Environment, Data Collection, College Students, School Holding Power, Dropouts, Online Courses, Academic Achievement},
ISSN = { EISSN-2227-7102},
Type = {Journal Articles, Information Analyses},
}


@article{ED630852,
Title = {Analysis of an Explainable Student Performance Prediction Model in an Introductory Programming Course},
Author = {Hoq, Muntasir and Brusilovsky, Peter and Akram, Bita},
Journal = {International Educational Data Mining Society},
Year = {2023},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED630852},
Abstract = {Prediction of student performance in introductory programming courses can assist struggling students and improve their persistence. On the other hand, it is important for the prediction to be transparent for the instructor and students to effectively utilize the results of this prediction. Explainable Machine Learning models can effectively help students and instructors gain insights into students' different programming behaviors and problem-solving strategies that can lead to good or poor performance. This study develops an explainable model that predicts students' performance based on programming assignment submission information. We extract different data-driven features from students' programming submissions and employ a stacked ensemble model to predict students' final exam grades. We use SHAP, a game-theory-based framework, to explain the model's predictions to help the stakeholders understand the impact of different programming behaviors on students' success. Moreover, we analyze the impact of important features and utilize a combination of descriptive statistics and mixture models to identify different profiles of students based on their problem-solving patterns to bolster explainability. The experimental results suggest that our model significantly outperforms other Machine Learning models, including KNN, SVM, XGBoost, Bagging, Boosting, and Linear regression. Our explainable and transparent model can help explain students' common problem-solving patterns in relationship with their level of expertise resulting in effective intervention and adaptive support to students. [For the complete proceedings, see ED630829.]},
Keywords = {Academic Achievement, Prediction, Models, Introductory Courses, Programming, Artificial Intelligence, Grades (Scholastic)},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1400817,
Title = {Student Performance Prediction Using Datamining Classification Algorithms: Evaluating Generalizability of Models from Geographical Aspect},
Author = {Parhizkar, Amirmohammad and Tejeddin, Golnaz and Khatibi, Toktam},
Journal = {Education and Information Technologies},
Year = {2023},
Volume = {28},
Pages = {14167-14185},
DOI = {http://eric.ed.gov/?id=EJ1400817},
Abstract = {Increasing productivity in educational systems is of great importance. Researchers are keen to predict the academic performance of students; this is done to enhance the overall productivity of educational system by effectively identifying students whose performance is below average. This universal concern has been combined with data science leading to the creation of an interdisciplinary research area called Educational Data Mining. One of the recent issues which has been addressed by researchers is training generalizable models from different aspects such as gender, major, geography and etc. Therefore, in this research we use machine learning methods to predict student's performance, emphasizing on training generalizable models from geographical aspect. For this purpose, a questionnaire containing 37 questions was designed, through which 536 answers were collected, including 111 international and 425 domestic answers. According to the literature, student performance is mostly determined based on the GPA (grade point average) of the entire course. In this research, information about the GPA of respondents in undergraduate and graduate courses was collected in the form of three classes. After a final review of the models employed in previous studies, the main models selected and used for classification purposes included SVM, CNN, Adaboost, RF, SVM, and DT. Feature selection is performed using XGBoost, random forest, as well as SVML1. The main issue investigated in this study is the generalizability of the models trained on domestic (Iranian) data and tested on international data (non-Iranian). Experimental results show that the best models trained with specific dataset collected in this research had generalizability comparing to base models' outcomes which were trained and tested on domestic data. Meanwhile, Random forest and CNN models shows the best performance with the average of accuracy and F-score of 73.5 and 68.5, respectively.},
Keywords = {Algorithms, Grade Point Average, Interdisciplinary Approach, Prediction, Academic Achievement, Data Analysis, Learning Analytics, Gender Differences, Majors (Students), Geographic Location, Student Characteristics, Foreign Students, Undergraduate Students, Comparative Analysis, Graduate Students, Classification, Models, Generalization, Computer Software, Accuracy},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1400798,
Title = {Predicting Students' Academic Performance by Mining the Educational Data through Machine Learning-Based Classification Model},
Author = {Nayak, Padmalaya and Vaheed, Sk. and Gupta, Surbhi and Mohan, Neeraj},
Journal = {Education and Information Technologies},
Year = {2023},
Volume = {28},
Pages = {14611-14637},
DOI = {http://eric.ed.gov/?id=EJ1400798},
Abstract = {Students' academic performance prediction is one of the most important applications of Educational Data Mining (EDM) that helps to improve the quality of the education process. The attainment of student outcomes in an Outcome-based Education (OBE) system adds invaluable rewards to facilitate corrective measures to the learning processes. Furthermore, the explosive increase of e-learning platforms generates a large volume of data that demands the extraction of useful information using up-to-date techniques. Keeping this view in mind and to check the impact of various features on student outcomes during online classes, we have analyzed two sets of datasets; the Kalboard 360 dataset (a larger dataset) that contains academic, demographic as well as behavioral features which have been observed and recorded during the classes held and a local Institute dataset that does not acquire behavioral features. To achieve this, we have selected a few machine learning algorithms such as Decision Tree (J48), Naïve Bayes (NB), Random Forest (RF), and Multilayer Perceptron (MLP) to classify the students, along with a few filter-based feature selection methods like Info gain, gain ratio, and correlation features have been applied to select the key attributes. Finally, we have fine-tuned the learning parameters of MLP called "Opt-MLP" to get an optimized output and compared it with other classification models. Our experimental results conclude that Opt-MLP proves its superiority over other classification models by predicting an accuracy of 87.14% without the feature selection (WOFS) and 90.74% accuracy with the feature selection (WFS) method for data set 1 and an accuracy of 79.37% without feature selection and 97.08% with feature selection for dataset 2. But, when the students' behavioral feature is considered along with other features, the RF model provides 100% accuracy justifying that students' behavior during class hours has a great impact on attaining the students' outcomes.},
Keywords = {Predictor Variables, Academic Achievement, Data Collection, Information Retrieval, Classification, Electronic Learning, Learning Processes, Artificial Intelligence, Algorithms, Bayesian Statistics, Accuracy},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED629740,
Title = {A Comparison of Machine Learning Algorithms for Predicting Student Performance in an Online Mathematics Game},
Author = {Ji-Eun Lee and Amisha Jindal and Sanika Nitin Patki and Ashish Gurung and Reilly Norum and Erin Ottmar},
Journal = {Grantee Submission},
Year = {2022},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED629740},
Abstract = {This paper demonstrates how to apply Machine Learning (ML) techniques to analyze student interaction data collected in an online mathematics game. We examined: (1) how different ML algorithms influenced the precision of middle-school students' (N = 359) performance prediction; and (2) what types of in-game features were associated with student math knowledge scores. The results indicated that the Random Forest algorithm showed the best performance in predicting posttest math knowledge scores among the seven algorithms employed. Out of 37 features included in the model, the validity of the students' first mathematical transformation was the most predictive of their math knowledge scores. Implications for game learning analytics and supporting students' algebraic learning are discussed based on the findings.},
Keywords = {Teaching Methods, Algorithms, Mathematics Tests, Computer Games, Learning Analytics, Interaction Process Analysis, Middle School Students, Anxiety, Mathematics Instruction, Models, Validity, Algebra, Learning Processes, Computer Assisted Instruction, Comparative Analysis, Mathematical Concepts, Concept Formation, Sampling, Correlation, Scores, Prediction},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1430146,
Title = {A Data-Driven Precision Teaching Intervention Mechanism to Improve Secondary School Students' Learning Effectiveness},
Author = {Yu-Jie Wang and Chang-Lei Gao and Xin-Dong Ye},
Journal = {Education and Information Technologies},
Year = {2024},
Volume = {29},
Pages = {11645-11673},
DOI = {http://eric.ed.gov/?id=EJ1430146},
Abstract = {The continuous development of Educational Data Mining (EDM) and Learning Analytics (LA) technologies has provided more effective technical support for accurate early warning and interventions for student academic performance. However, the existing body of research on EDM and LA needs more empirical studies that provide feedback interventions, and more attention should be paid to primary and secondary school students. This study proposed a data-driven precision teaching intervention mechanism combining EDM and LA technologies. The proposed mechanism aims to assist teachers in predicting students' academic performance and implementing corresponding interventions. This approach enables early warnings and reminders for students in crisis, and offers teaching assistance and support tailored to students at different levels. A quasi-experimental design was employed to examine the impact of the data-driven precision teaching intervention mechanism on secondary school students' learning outcomes. A total of 142 seventh-grade students participated in the intervention experiment, with an experimental group (50) receiving the data-driven precision teaching intervention, control group2 (48) receiving a group intervention stratified by teacher experience, and control group1 (44) receiving a traditional group intervention. Posttest data were collected after three rounds of intervention. Compared to the two control groups, students in the experimental group demonstrated superior academic achievement, intrinsic motivation, self-efficacy, and meta-cognitive awareness. These findings indicate that the data-driven precision teaching intervention approach positively impacted students' academic development, and effectively promoted their personalized learning. The findings provide pedagogical insights into the application of EDM in conjunction with LA prediction and actionable interventions.},
Keywords = {Precision Teaching, Data Use, Intervention, Educational Improvement, Secondary School Students, Instructional Improvement, Learning Analytics, Prediction, Academic Achievement, Outcomes of Education, Grade 7, Data Analysis},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1332489,
Title = {Student Performance Prediction, Risk Analysis, and Feedback Based on Context-Bound Cognitive Skill Scores},
Author = {MD, Soumya and Krishnamoorthy, Shivsubramani},
Journal = {Education and Information Technologies},
Year = {2022},
Volume = {27},
Pages = {3981-4005},
DOI = {http://eric.ed.gov/?id=EJ1332489},
Abstract = {In recent times, Educational Data Mining and Learning Analytics have been abundantly used to model decision-making to improve teaching/learning ecosystems. However, the adaptation of student models in different domains/courses needs a balance between the generalization and context specificity to reduce the redundancy in creating domain-specific models. This paper explores the predictive power and generalization of a feature--"context-bound cognitive skill score"--in estimating the likelihood of success or failure of a student in a traditional higher education course so that the appropriate intervention is provided to help the students. To identify the students at risk in different courses, we applied classification algorithms on "context-bound cognitive skill scores" of a student to estimate the chances of success or failure, especially failure. The context-bound cognitive skill scores were aggregated based on the learning objective of a course to generate meaningful visual feedback to teachers and students so that they can understand why some students are predicted to be at risk. Evaluation of the generated model shows that this feature is applicable in a range of courses, and it mitigates the effort in engineering features/models for each domain. We submit that overall, "context-bound cognitive skill scores" prove to be effective in flagging the student performance when the accurate metrics related to learning activities and social behaviors of the students are unavailable.},
Keywords = {Predictor Variables, Academic Achievement, Higher Education, Learning Analytics, Prediction, Cognitive Ability, Scores, At Risk Students, Classification, Generalization},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1437363,
Title = {Early Prediction of Student Academic Performance Based on Machine Learning Algorithms: A Case Study of Bachelor's Degree Students in KSA},
Author = {Mouna Ben Said and Yessine Hadj Kacem and Abdulmohsen Algarni and Atef Masmoudi},
Journal = {Education and Information Technologies},
Year = {2024},
Volume = {29},
Pages = {13247-13270},
DOI = {http://eric.ed.gov/?id=EJ1437363},
Abstract = {In the current educational landscape, where large amounts of data are being produced by institutions, Educational Data Mining (EDM) emerges as a critical discipline that plays a crucial role in extracting knowledge from this data to help academic policymakers make decisions. EDM has a primary focus on predicting students' academic performance. Numerous studies have been conducted for this purpose, but they are plagued by challenges including limited dataset size, disparities in grade distributions, and feature selection issues. This paper introduces a Machine Learning (ML) based method for the early prediction of bachelor students' final academic grade as well as drop-out cases. It focuses on identifying, from the first semester of study, the students requiring specific attention because of their academic weaknesses. The research employs nine classification models on students' data from a Saudi university, subsequently implementing a majority voting algorithm. The experimental outcomes are noteworthy, with the Extra Trees (ET) algorithm achieving a promising accuracy of 82.8% and the Majority Voting (MV) model outperforming all existing models by an accuracy reaching 92.7%. Moreover, the study identifies the factors exerting the greatest impact on students' academic performance, which belong to the three considered feature types: demographic, pre-admission, and academic.},
Keywords = {Prediction, Academic Achievement, Artificial Intelligence, Algorithms, Undergraduate Students, Foreign Countries, Grades (Scholastic)},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1243672,
Title = {The Potential for Student Performance Prediction in Small Cohorts with Minimal Available Attributes},
Author = {Wakelam, Edward and Jefferies, Amanda and Davey, Neil and Sun, Yi},
Journal = {British Journal of Educational Technology},
Year = {2020},
Volume = {51},
Pages = {347-370},
DOI = {http://eric.ed.gov/?id=EJ1243672},
Abstract = {The measurement of student performance during their progress through university study provides academic leadership with critical information on each student's likelihood of success. Academics have traditionally used their interactions with individual students through class activities and interim assessments to identify those "at risk" of failure/withdrawal. However, modern university environments, offering easy on-line availability of course material, may see reduced lecture/tutorial attendance, making such identification more challenging. Modern data mining and machine learning techniques provide increasingly accurate predictions of student examination assessment marks, although these approaches have focussed upon large student populations and wide ranges of data attributes per student. However, many university modules comprise relatively small student cohorts, with institutional protocols limiting the student attributes available for analysis. It appears that very little research attention has been devoted to this area of analysis and prediction. We describe an experiment conducted on a final-year university module student cohort of 23, where individual student data are limited to lecture/tutorial attendance, virtual learning environment accesses and intermediate assessments. We found potential for predicting individual student interim and final assessment marks in small student cohorts with very limited attributes and that these predictions could be useful to support module leaders in identifying students potentially "at risk."},
Keywords = {Academic Achievement, At Risk Students, Data Analysis, Identification, Academic Failure, Dropouts, Computer Assisted Instruction, Student Characteristics, Computer Simulation, Grades (Scholastic), Prediction, Attendance, College Seniors, Lecture Method},
ISSN = { ISSN-0007-1013},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1368137,
Title = {Predicting Students' Performance in English and Mathematics Using Data Mining Techniques},
Author = {Roslan, Muhammad Haziq Bin and Chen, Chwen Jen},
Journal = {Education and Information Technologies},
Year = {2023},
Volume = {28},
Pages = {1427-1453},
DOI = {http://eric.ed.gov/?id=EJ1368137},
Abstract = {This study attempts to predict secondary school students' performance in English and Mathematics subjects using data mining (DM) techniques. It aims to provide insights into predictors of students' performance in English and Mathematics, characteristics of students with different levels of performance, the most effective DM technique for students' performance prediction, and the relationship between these two subjects. The study employed the archival data of students who were 16 years old in 2019 and sat for the Malaysian Certificate of Examination (MCE) in 2021. The learning of English and Mathematics is a concern in many countries. Three main factors, namely students' past academic performance, demographics, and psychological attributes were scrutinized to identify their impact on the prediction. This study utilized the Orange software for the DM process. It employed Decision Tree (DT) rules to determine the characteristics of students with low, moderate, and high performance in English and Mathematics subjects. DT and Naïve Bayes (NB) techniques show the best predictive performance for English and Mathematics subjects, respectively. Such characteristics and predictions may cue appropriate interventions to improve students' performance in these subjects. This study revealed students' past academic performance as the most critical predictor, as well as a few demographics and psychological attributes. By examining top predictors derived using four different classifier types, this study found that students' past Mathematics performance predicts their MCE English performance and students' past English performance predicts their MCE Mathematics performance. This finding shows students' performances in both subjects are interrelated.},
Keywords = {Foreign Countries, Secondary School Students, Academic Achievement, English Instruction, Mathematics Achievement, Data Use, Information Retrieval, Pattern Recognition, Data Analysis, Information Technology, Prior Learning, Psychological Patterns, Predictor Variables, Student Characteristics},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1336842,
Title = {HELA: A Novel Hybrid Ensemble Learning Algorithm for Predicting Academic Performance of Students},
Author = {Keser, Sinem Bozkurt and Aghalarova, Sevda},
Journal = {Education and Information Technologies},
Year = {2022},
Volume = {27},
Pages = {4521-4552},
DOI = {http://eric.ed.gov/?id=EJ1336842},
Abstract = {Education plays a major role in the development of the consciousness of the whole society. Education has been improved by analyzing educational data related to student academic performance. By using data mining techniques and algorithms on data from the educational environment, students' performances can be predicted. In this study, a novel Hybrid Ensemble Learning Algorithm (HELA) is proposed to predict the academic performance of students. The prediction results obtained from base classifiers namely Gradient Boosting, Extreme Gradient Boosting, Light Gradient Boosting Machine, and different combinations of these algorithms are given as input to the Super Learner algorithm. Hyper-parameters of base classifiers are optimized with a Random Search algorithm. Students' performances in Math and Portuguese classes are predicted by the proposed algorithm. In the experimental results, 96.6% and 91.2% accuracy values are obtained for the Mathematics course, and the Portuguese course, respectively. This paper is the first study, to our knowledge, to integrate the boosting and stacking-based ensemble learning algorithm for the prediction of students' academic performance that gives better predictive results with high efficiency.},
Keywords = {Grade Prediction, Academic Achievement, Data Analysis, Data Collection, Mathematics, Evaluation Methods},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED608050,
Title = {Towards Fair Educational Data Mining: A Case Study on Detecting At-Risk Students},
Author = {Hu, Qian and Rangwala, Huzefa},
Journal = {International Educational Data Mining Society},
Year = {2020},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED608050},
Abstract = {Over the past decade, machine learning has become an integral part of educational technologies. With more and more applications such as students' performance prediction, course recommendation, dropout prediction and knowledge tracing relying upon machine learning models, there is increasing evidence and concerns about bias and unfairness of these models. Unfair models can lead to inequitable outcomes for some groups of students and negatively impact their learning. We show by real-world examples that educational data has embedded bias that leads to biased student modeling, which urges the development of fairness formalizations and fair algorithms for educational applications. Several formalizations of fairness have been proposed that can be classified into two types: (i) group fairness and (ii) individual fairness. Group fairness guarantees that groups are treated fairly as a whole, which might not be fair to some individuals. Thus individual fairness has been proposed to make sure fairness is achieved on individual level. In this work, we focus on developing an individually fair model for identifying students at-risk of underperforming. We propose a model which is based on the idea that the prediction for a student (identifying at-risk students) should not be influenced by his/her sensitive attributes. The proposed model is shown to effectively remove bias from these predictions and hence, making them useful in aiding all students. [For the full proceedings, see ED607784.]},
Keywords = {Artificial Intelligence, Bias, Learning Analytics, Statistical Analysis, Models, Prediction, At Risk Students, Classification, Mathematics},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1415377,
Title = {The Impact of Big Five Personality Trait in Predicting Student Academic Performance},
Author = {Fathi Said Emhemed Shaninah and Mohd Halim Mohd Noor},
Journal = {Journal of Applied Research in Higher Education},
Year = {2024},
Volume = {16},
Pages = {523-539},
DOI = {http://eric.ed.gov/?id=EJ1415377},
Abstract = {Purpose: The study aims to propose a predictive model that combines personality and demographic factors to predict student academic performance (SAP). This research study works on understanding, enhancing and applying techniques to enhance the prediction of SAP. Design/methodology/approach: The authors gathered information from 305 university students from Al-Zintan University Libya. The study uses a survey questionnaire to collect data on essential variables. The purpose of the questionnaire is to discover variables that affect students' academic performance. The survey questionnaire has 44 closed questions with Likert scale designs that were distributed to a variety of college students at the start of the first semester of 2022. It includes questions about demographics, personality, employment and institutional aspects. The authors proposed a predictive model to identify the main fundamental components, consisting of one dependent variable (SAP) and five independent constructs. The suggested model is tested using partial least squares (PLS) and structural equation modeling (SEM), which perform better than covariance-based structural equation modeling (CB-SEM). PLS-SEM performs well with smaller sample sizes, even for complicated models. Findings: The study results show that the proposed model accurately predicted the student's academic performance. The personality trait variables are a key factor that determines the actual student's academic performance. The student's academic performance is significantly impacted by each variable in the personality trait variables as well. Originality/value: The process of validating research was done empirically through the accuracy and efficiency of model performance. The study differs from previous studies in that it accumulated a wide range of factors from different dimensions, including student demographics and personality trait factors. The authors developed a structural equation model to predict students' academic performance.},
Keywords = {Foreign Countries, Academic Achievement, Personality Traits, Predictor Variables, Student Attitudes, Undergraduate Students},
ISSN = { ISSN-2050-7003},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1397277,
Title = {Enhancing the Prediction of Student Performance Based on the Machine Learning XGBoost Algorithm},
Author = {Asselman, Amal and Khaldi, Mohamed and Aammou, Souhaib},
Journal = {Interactive Learning Environments},
Year = {2023},
Volume = {31},
Pages = {3360-3379},
DOI = {http://eric.ed.gov/?id=EJ1397277},
Abstract = {Performance Factors Analysis (PFA) is considered one of the most important Knowledge Tracing (KT) approaches used for constructing adaptive educational hypermedia systems. It has shown a high prediction accuracy against many other KT approaches. While, the desire to estimate more accurately the student level leads researchers to enhance PFA by inventing several advanced extensions. However, most of the proposed extensions have exclusively been improved in a pedagogical sense, as the improvements have mostly been limited to the analysis of students' behaviour during their learning process. In contrast, Machine Learning provides many powerful methods that could be efficient to enhance, in the technical sense, the prediction of student performance. Our goal is to focus on the exploitation of Ensemble Learning methods as an extremely effective Machine Learning paradigm used to create many advanced solutions in several fields. In this sense, we propose a new PFA approach based on different models (Random Forest, AdaBoost, and XGBoost) in order to increase the predictive accuracy of student performance. Our models have been evaluated on three different datasets. The experimental results show that the scalable XGBoost has outperformed the other evaluated models and substantially improved the performance prediction compared to the original PFA algorithm.},
Keywords = {Algorithms, Artificial Intelligence, Factor Analysis, Student Behavior, Accuracy, Prediction, Academic Achievement, Mathematics Instruction, Data Analysis, Middle School Students, High School Students, Physics},
ISSN = { ISSN-1049-4820},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1280948,
Title = {Student Performance Analysis and Prediction in Classroom Learning: A Review of Educational Data Mining Studies},
Author = {Khan, Anupam and Ghosh, Soumya K.},
Journal = {Education and Information Technologies},
Year = {2021},
Volume = {26},
Pages = {205-240},
DOI = {http://eric.ed.gov/?id=EJ1280948},
Abstract = {Student performance modelling is one of the challenging and popular research topics in educational data mining (EDM). Multiple factors influence the performance in non-linear ways; thus making this field more attractive to the researchers. The widespread availability of educational datasets further catalyse this interestingness, especially in online learning. Although several EDM surveys are available in the literature, we could find only a few specific surveys on student performance analysis and prediction. These specific surveys are limited in nature and primarily focus on studies that try to identify possible predictor or model student performance. However, the previous works do not address the temporal aspect of prediction. Moreover, we could not find any such specific survey which focuses only on classroom-based education. In this paper, we present a systematic review of EDM studies on student performance in classroom learning. It focuses on identifying the predictors, methods used for such identification, time and aim of prediction. It is significantly the first systematic survey of EDM studies that consider only classroom learning and focuses on the temporal aspect as well. This paper presents a review of 140 studies in this area. The meta-analysis indicates that the researchers achieve significant prediction efficiency during the tenure of the course. However, performance prediction before course commencement needs special attention.},
Keywords = {Academic Achievement, Prediction, Data Analysis, Meta Analysis, Identification, Models},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Information Analyses},
Language = {English},
}


@article{EJ1351625,
Title = {Categorizing Well-Written Course Learning Outcomes Using Machine Learning},
Author = {Hadj Kacem, Yessine and Alshehri, Safa and Qaid, Talal},
Journal = {Journal of Information Technology Education: Innovations in Practice},
Year = {2022},
Volume = {21},
Pages = {61-75},
DOI = {http://eric.ed.gov/?id=EJ1351625},
Abstract = {Aim/Purpose: This paper presents a machine learning approach for analyzing Course Learning Outcomes (CLOs). The aim of this study is to find a model that can check whether a CLO is well written or not. Background: The use of machine learning algorithms has been, since many years, a prominent solution to predict learner performance in Outcome Based Education. However, the CLOs definition is still presenting a big handicap for faculties. There is a lack of supported tools and models that permit to predict whether a CLO is well written or not. Consequently, educators need an expert in quality and education to validate the outcomes of their courses. Methodology: A novel method named CLOCML (Course Learning Outcome Classification using Machine Learning) is proposed in this paper to develop predictive models for CLOs paraphrasing. A new dataset entitled CLOC (Course Learning Outcomes Classes) for that purpose has been collected and then undergone a pre-processing phase. We compared the performance of 4 models for predicting a CLO classification. Those models are Support Vector Machine (SVM), Random Forest, Naive Bayes and XGBoost. Contribution: The application of CLOCML may help faculties to make well-defined CLOs and then correct CLOs' measures in order to improve the quality of education addressed to their students. Findings: The best classification model was SVM. It was able to detect the CLO class with an accuracy of 83%. Recommendations for Practitioners: We would recommend both faculties' members and quality reviewers to make an informed decision about the nature of a given course outcome. Recommendation for Researchers: We would highly endorse that the researchers apply more machine learning models for CLOs of various disciplines and compare between them. We would also recommend that future studies investigate on the importance of the definition of CLOs and its impact on the credibility of Key Performance Indicators (KPIs) values during accreditation process. Impact on Society: The findings of this study confirm the results of several other researchers who use machine learning in outcome-based education. The definition of right CLOs will help the student to get an idea about the performances that will be measured at the end of a course. Moreover, each faculty can take appropriate actions and suggest suitable recommendations after right performance measures in order to improve the quality of his course. Future Research: Future research can be improved by using a larger dataset. It could also be improved with deep learning models to reach more accurate results. Indeed, a strategy for checking CLOs overlaps could be integrated.},
Keywords = {Outcomes of Education, Artificial Intelligence, Educational Assessment, Classification, Predictor Variables, Educational Quality, Higher Education, Courses},
ISSN = { ISSN-2165-3151},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1438278,
Title = {Manual Label and Machine Learning in Clustering and Predicting Student Performance: A Practice Based on Web-Interactive Teaching Systems},
Author = {Mengjiao Yin and Hengshan Cao and Zuhong Yu and Xianyu Pan},
Journal = {International Journal of Web-Based Learning and Teaching Technologies},
Year = {2024},
Volume = {19},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1438278},
Abstract = {This study presents the Academic Investment Model (AIM) as a novel approach to predicting student academic performance by incorporating learning styles as a predictive feature. Utilizing data from 138 Marketing students across China, the research employs a combination of machine learning clustering methods and manual feature engineering through a four-quadrant clustering technique. The AIM model delineates student investment into four quadrants based on their time and energy commitment to academic pursuits, distinguishing between result-oriented and process-oriented investments. The findings reveal that the four-quadrant method surpasses machine learning clustering in predictive accuracy, highlighting the robustness of manual feature engineering. The study's significance lies in its potential to guide educators in designing targeted interventions and personalized learning strategies, emphasizing the importance of process-oriented assessment in education. Future research is recommended to expand the sample size and explore the integration of deep learning models for validation.},
Keywords = {Predictor Variables, Artificial Intelligence, Performance, Cluster Grouping, Learning Modalities, Foreign Countries, Business Administration Education, Individualized Instruction, Intervention, Undergraduate Students},
ISSN = { ISSN-1548-1093},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1283035,
Title = {Student Performance Prediction Based on Blended Learning},
Author = {Xu, Zhuojia and Yuan, Hua and Liu, Qishan},
Journal = {IEEE Transactions on Education},
Year = {2021},
Volume = {64},
Pages = {66-73},
DOI = {http://eric.ed.gov/?id=EJ1283035},
Abstract = {Contribution: This article explored blended learning by implementing a student-centered teaching method based on the flipped classroom and small private online course (SPOC). The impact of general online learning behavior on student performance was analyzed. This work is practical and provides enlightenment for learning analysis and individualized teaching in blended learning. Background: Providing individualized teaching in a large class is an effective way to improve teaching quality, but the traditional teaching method makes it difficult for teachers to learn about each student's learning situation. Blended learning offers the possibility of individualized teaching for teachers. The combination of flipped classroom and SPOC is a good way to implement blended learning, but few studies have verified the predictability of learning performance in such a scenario to explore individualized teaching. Intended Outcomes: Students' behavior in blended learning can be used to predict their learning outcomes, and the implementation method is reproducible. Teachers can implement individualized teaching in blended learning. Application Design: The learning activities were designed and reconstructed to create a blended learning scenario, data that depict students' learning behavior were collected and used to predict their performance by a multiple regression model. Student performance was measured by the final offline exam, and its predictability in the 1/4, 1/2, and 3/4 semester was tested for early intervention. Findings: The results show that students' online behavior can be predictors of their performance, and with the advance of the course, the predicted results are more stable and reliable.},
Keywords = {Academic Achievement, Blended Learning, Prediction, Performance Factors, Student Centered Learning, Electronic Learning, Online Courses, Small Classes, Individualized Instruction, Student Behavior, Learning Analytics},
ISSN = { ISSN-0018-9359},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1341021,
Title = {MOOC Performance Prediction and Personal Performance Improvement via Bayesian Network},
Author = {Hao, Jia and Gan, Jianhou and Zhu, Luyu},
Journal = {Education and Information Technologies},
Year = {2022},
Volume = {27},
Pages = {7303-7326},
DOI = {http://eric.ed.gov/?id=EJ1341021},
Abstract = {In order to analyze the non-linear and uncertain relationships among the student-related features, curriculum-related features as well as the environment-related features, and then quantify the corresponding impacts on students' final MOOC performance in a valid way, we first construct a Students' performance Prediction Bayesian Network (SPBN) via the hill-climbing and maximum likelihood estimation (MLE) method. With SPBN, we can predict the students' MOOC performance and then quantify the uncertain dependencies of all the relevant features. Furthermore, with the prediction results of SPBN, we further apply the genetic algorithm (GA) to offer the personal performance improvement suggestions for those who are about to fail the courses according to different students' background and their current engagement behaviors, so as to avoid the MOOC exam failures in advance. The experiments conducted on the Open University Learning Analytics Dataset (OULAD) have shown that the SPBN can predict students' performance in MOOC accurately, and the GA-based method can offer the reasonable performance improvement suggestions effectively.},
Keywords = {Online Courses, Academic Achievement, Prediction, Student Improvement, Bayesian Statistics},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1424560,
Title = {Framework for Suggesting Corrective Actions to Help Students Intended at Risk of Low Performance Based on Experimental Study of College Students Using Explainable Machine Learning Model},
Author = {Harsimran Singh and Banipreet Kaur and Arun Sharma and Ajeet Singh},
Journal = {Education and Information Technologies},
Year = {2024},
Volume = {29},
Pages = {7997-8034},
DOI = {http://eric.ed.gov/?id=EJ1424560},
Abstract = {Today, the main aim of educational institutes is to provide a high level of education to students, as career selection is one of the most important and quite difficult decisions for learners, so it is essential to examine students' capabilities and interests. Higher education institutions frequently face higher dropout rates, low academic achievement, and graduation delays. One potential answer to these issues is to better leverage student data stored in institutional databases and online learning platforms to forecast students' academic achievements early by using artificial intelligence and advanced computer algorithms. Several research projects have been launched with the goal of building systems that can predict student performance. However, a system that can forecast student performance and identify the various factors that directly impact it is required. The purpose of this research work is to create a model that correctly identifies students who are in danger of low performance, as well as to identify the factors that contribute to this phenomenon and suggesting the remedial actions so as to reduce dropout rate and low performance among students. The emphasis of this study is to explore various factors that may affect mental health which lead to low performance or loss of interest in studies. The developed model can accurately identify at-risk students with over 96.5% accuracy using Machine learning techniques. This study focuses extensively on various factors apart from academics, such as personal and family factors and their association with student performance. To increase the accuracy of performance predictions, the model combines explainable Machine learning techniques to outline the factors associated with poor performance and discusses a novel framework that will help to increase the accuracy of prediction of the established prediction system. This assists low-performing students in improving their academic metrics by executing corrective actions that address the issues. The proposed novel framework, with the help of a mapping table, will recommend corrective actions along with visualization using the heatmap technique which may help the students to perform better in exams, increase the institution's effectiveness, and improves any country's economic growth and stability.},
Keywords = {College Students, At Risk Students, Academic Achievement, Artificial Intelligence, Models, Identification, Technology Uses in Education, Prediction, Influences, Remedial Instruction, Dropout Prevention, Mental Health, Student Interests},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Evaluative},
Language = {English},
}


@article{EJ1402675,
Title = {Predicting Secondary School Students' Academic Achievement from Their Elementary School Performance and Learning Behaviours: A Longitudinal Study Based on South Korea's National Assessment of Educational Achievement},
Author = {Yi, Hyun Sook and Na, Wooyoul and Lee, Changmook},
Journal = {Asia Pacific Journal of Education},
Year = {2023},
Volume = {43},
Pages = {1031-1048},
DOI = {http://eric.ed.gov/?id=EJ1402675},
Abstract = {Academic achievement is an important factor strongly related to positive educational experiences that facilitate subsequent learning. Therefore, identifying students who need support at an early stage and promptly providing appropriate intervention play a crucial role in preventing learning deficits. This study examined the longitudinal change in elementary school students' proficiency status to understand the nature of longitudinal transitions. It explored the feasibility of developing early predictive models for identifying students potentially facing academic difficulties based on information obtained from elementary school. Deep neural network and hierarchical generalized linear models were applied to large-scale national assessment panel data collected within the framework of an accountability system in South Korea. The results showed that although most students maintained their initial proficiency status, a substantial number of students made longitudinal transitions from non-proficiency to proficiency or vice-versa as they progressed from elementary to high school. The predictive models had an acceptable level of accuracy in predicting future academic performance, considering the degree of student mobility across proficiency levels over grades. The study concluded that the predictive models can serve as a starting point to identify students who need assistance and provide educators with a means to intervene promptly.},
Keywords = {Secondary School Students, Academic Achievement, Grade Prediction, Elementary Education, Student Behavior, Foreign Countries, Longitudinal Studies, Cognitive Processes},
ISSN = { ISSN-0218-8791},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1362228,
Title = {Integration of Artificial Intelligence Performance Prediction and Learning Analytics to Improve Student Learning in Online Engineering Course},
Author = {Ouyang, Fan and Wu, Mian and Zheng, Luyi and Zhang, Liyin and Jiao, Pengcheng},
Journal = {International Journal of Educational Technology in Higher Education},
Year = {2023},
Volume = {20},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1362228},
Abstract = {As a cutting-edge field of artificial intelligence in education (AIEd) that depends on advanced computing technologies, AI performance prediction model is widely used to identify at-risk students that tend to fail, establish student-centered learning pathways, and optimize instructional design and development. A majority of the existing AI prediction models focus on the development and optimization of the accuracy of AI algorithms rather than applying AI models to provide student with in-time and continuous feedback and improve the students' learning quality. To fill this gap, this research integrated an AI performance prediction model with learning analytics approaches with a goal to improve student learning effects in a collaborative learning context. Quasi-experimental research was conducted in an online engineering course to examine the differences of students' collaborative learning effect with and without the support of the integrated approach. Results showed that the integrated approach increased student engagement, improved collaborative learning performances, and strengthen student satisfactions about learning. This research made contributions to proposing an integrated approach of AI models and learning analytics (LA) feedback and providing paradigmatic implications for future development of AI-driven learning analytics.},
Keywords = {Technology Integration, Artificial Intelligence, Performance, Prediction, Learning Analytics, Educational Improvement, Academic Achievement, Online Courses, Engineering Education, Cooperative Learning, Instructional Design, Student Centered Learning, At Risk Students, Student Satisfaction, Models},
ISSN = { EISSN-2365-9440},
Type = {Journal Articles, Reports - Research, Tests/Questionnaires},
Language = {English},
}


@article{ED615629,
Title = {Student Performance Prediction Using Dynamic Neural Models},
Author = {Delianidi, Marina and Diamantaras, Konstantinos and Chrysogonidis, George and Nikiforidis, Vasileios},
Journal = {International Educational Data Mining Society},
Year = {2021},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED615629},
Abstract = {We address the problem of predicting the correctness of the student's response on the next exam question based on their previous interactions in the course of their learning and evaluation process. We model the student performance as a dynamic problem and compare the two major classes of dynamic neural architectures for its solution, namely the finite-memory Time Delay Neural Networks (TDNN) and the potentially infinite-memory Recurrent Neural Networks (RNN). Since the next response is a function of the knowledge state of the student and this, in turn, is a function of their previous responses and the skills associated with the previous questions, we propose a two-part network architecture. The first part employs a dynamic neural network (either TDNN or RNN) to trace the student knowledge state. The second part applies on top of the dynamic part and it is a multi-layer feed-forward network which completes the classification task of predicting the student response based on our estimate of the student knowledge state. Both input skills and previous responses are encoded using different embeddings. Regarding the skill embeddings we tried two different initialization schemes using (a) random vectors and (b) pretrained vectors matching the textual descriptions of the skills. Our experiments show that the performance of the RNN approach is better compared to the TDNN approach in all datasets that we have used. Also, we show that our RNN architecture outperforms the state-of-the-art models in four out of five datasets. It is worth noting that the TDNN approach also outperforms the state of the art models in four out of five datasets, although it is slightly worse than our proposed RNN approach. Finally, contrary to our expectations, we find that the initialization of skill embeddings using pretrained vectors offers practically no advantage over random initialization. [For the full proceedings, see ED615472.]},
Keywords = {Grade Prediction, Models, Student Experience, Cognitive Processes, Knowledge Representation},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1391276,
Title = {Data Mining: Will First-Year Results Predict the Likelihood of Completing Subsequent Units in Accounting Programs?},
Author = {Sithole, Seedwell T. M. and Ran, Guang and de Lange, Paul and Tharapos, Meredith and O'Connell, Brendan and Beatson, Nicola},
Journal = {Accounting Education},
Year = {2023},
Volume = {32},
Pages = {409-444},
DOI = {http://eric.ed.gov/?id=EJ1391276},
Abstract = {This study introduces data mining methods to accounting education scholarship to explore the relationship between accounting students' current academic performance (grades), demographic information, pre-university entrance scores and predicted academic performance. It adopts a C4.5 classification algorithm based on decision-tree analysis to examine 640 accounting students enrolled in an undergraduate accounting program at an Australian university. A significant contribution of this study is improved prediction of academic performance and identification of characteristics of students deemed to be at risk. By partitioning students into sub-groups based on tertiary entrance scores and employing clustering of study units, this study facilitates a more nuanced understanding of predictor attributes. Key findings were the dominance of a cluster of second year units in predicting students' later academic performance; that gender did not influence performance; and that performance in first year at university, rather than secondary school grades, was the most important predictor of subsequent academic performance.},
Keywords = {Data Analysis, Predictor Variables, Accounting, Educational Attainment, Grades (Scholastic), Student Characteristics, College Entrance Examinations, Academic Achievement, Undergraduate Students, Foreign Countries, Grade Prediction, Business Administration Education, College Faculty},
ISSN = { ISSN-0963-9284},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED624070,
Title = {Evaluating the Explainers: Black-Box Explainable Machine Learning for Student Success Prediction in MOOCs},
Author = {Swamy, Vinitra and Radmehr, Bahar and Krco, Natasa and Marras, Mirko and Käser, Tanja},
Journal = {International Educational Data Mining Society},
Year = {2022},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED624070},
Abstract = {Neural networks are ubiquitous in applied machine learning for education. Their pervasive success in predictive performance comes alongside a severe weakness, the lack of explainability of their decisions, especially relevant in humancentric fields. We implement five state-of-the-art methodologies for explaining black-box machine learning models (LIME, PermutationSHAP, KernelSHAP, DiCE, CEM) and examine the strengths of each approach on the downstream task of student performance prediction for five massive open online courses. Our experiments demonstrate that the families of explainers do not agree with each other on feature importance for the same Bidirectional LSTM models with the same representative set of students. We use Principal Component Analysis, Jensen-Shannon distance, and Spearman's rank-order correlation to quantitatively cross-examine explanations across methods and courses. Furthermore, we validate explainer performance across curriculum-based prerequisite relationships. Our results come to the concerning conclusion that the choice of explainer is an important decision and is in fact paramount to the interpretation of the predictive results, even more so than the course the model is trained on. Source code and models are released at http://github.com/epfl-ml4ed/evaluating-explainers. [For the full proceedings, see ED623995.]},
Keywords = {Artificial Intelligence, Academic Achievement, Grade Prediction, MOOCs, Teaching Methods, Models},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{ED615582,
Title = {Knowledge Transfer by Discriminative Pre-Training for Academic Performance Prediction},
Author = {Kim, Byungsoo and Yu, Hangyeol and Shin, Dongmin and Choi, Youngduck},
Journal = {International Educational Data Mining Society},
Year = {2021},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED615582},
Abstract = {The needs for precisely estimating a student's academic performance have been emphasized with an increasing amount of attention paid to Intelligent Tutoring System (ITS). However, since labels for academic performance, such as test scores, are collected from outside of ITS, obtaining the labels is costly, leading to label-scarcity problem which brings challenge in taking machine learning approaches for academic performance prediction. To this end, inspired by the recent advancement of pre-training method in natural language processing community, we propose DPA, a transfer learning framework with Discriminative Pre-training tasks for Academic performance prediction. DPA pre-trains two models, a generator and a discriminator, and fine-tunes the discriminator on academic performance prediction. In DPA's pre-training phase, a sequence of interactions where some tokens are masked is provided to the generator which is trained to reconstruct the original sequence. Then, the discriminator takes an interaction sequence where the masked tokens are replaced by the generator's outputs, and is trained to predict the originalities of all tokens in the sequence. We conduct extensive experimental studies on a real-world dataset obtained from a multi-platform ITS application and show that DPA outperforms the previous state-of-the-art generative pre-training method with a reduction of 4.05% in mean absolute error and more robust to increased label-scarcity. [For the full proceedings, see ED615472.]},
Keywords = {Academic Achievement, Intelligent Tutoring Systems, Prediction, Scores, Natural Language Processing, Transfer of Training, Models, Learning Analytics, Computer Software, Handheld Devices, Telecommunications, Foreign Countries, Independent Study, Second Language Learning, Second Language Instruction, English (Second Language), Language Tests},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1396228,
Title = {KT-Bi-GRU: Student Performance Prediction with a Bi-Directional Recurrent Knowledge Tracing Neural Network},
Author = {Delianidi, Marina and Diamantaras, Konstantinos},
Journal = {Journal of Educational Data Mining},
Year = {2023},
Volume = {15},
Pages = {1-21},
DOI = {http://eric.ed.gov/?id=EJ1396228},
Abstract = {Student performance is affected by their knowledge which changes dynamically over time. Therefore, employing recurrent neural networks (RNN), which are known to be very good in dynamic time series prediction, can be a suitable approach for student performance prediction. We propose such a neural network architecture containing two modules: (i) a dynamic sub-network including a recurrent Bi-GRU layer used for knowledge state estimation, (ii) a non-dynamic, feed-forward sub-network for predicting answer correctness based on the current question and current student knowledge state. The model modifies our previously proposed architecture and is different from all other existing models because it estimates the student's knowledge state considering only their previous responses. Thus the dynamic sub-network generates more stable knowledge state vector representations since they are independent of the current question. We studied both single-skill and multi-skill question scenarios and employed embeddings to represent questions and responses. In the multi-skill case the initialization of the question embedding matrix with pretrained word-embeddings is found to improve model performance. The experimental results showed that our current KT-Bi-GRU model and the previous one have similar performance while both surpassed the performance of previous state-of-the-art knowledge tracing models for five out of seven datasets where in some cases, the difference is quite noticeable.},
Keywords = {Academic Achievement, Prediction, Cognitive Measurement, Bayesian Statistics, Models, Learning Processes, Brain, Cognitive Processes},
ISSN = { EISSN-2157-2100},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED615587,
Title = {Predicting Student Performance Using Teacher Observation Reports},
Author = {Fateen, Menna and Mine, Tsunenori},
Journal = {International Educational Data Mining Society},
Year = {2021},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED615587},
Abstract = {Studying for entrance examinations can be a distressing period for numerous students. Consequently, many students decide to attend cram schools to assist them in preparing for these exams. For such schools and for all educational institutes, it is necessary to obtain the best tools to provide the highest quality of learning and guidance. Performance prediction is one tool that can serve as a resource for insights that are valuable to all educational stakeholders. With accurate predictions of their grades, students can be further guided and fostered in order to achieve their optimal learning goals. In this regard, we target middle school students to be able to guide them on their educational journey as early as possible. We propose a method to predict the students' performance in entrance examinations using the comments that cram school teachers made throughout the lessons. Teachers in cram schools observe their student's behavior closely and give reports on the efforts taken in their subject material. We show that the teachers' comments are qualified to construct a tool that is capable of predicting students' grades efficiently. This is a new method because previous studies focus on predicting grades mainly using student data such as their reflection comments or earlier scores. Experimental results show that using readily available feedback from teachers can remarkably contribute to the accuracy of student performance prediction. [For the full proceedings, see ED615472.]},
Keywords = {Grade Prediction, Academic Achievement, Observation, Middle School Students, Artificial Intelligence, Foreign Countries, Tutorial Programs},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1360979,
Title = {Objectively Measuring Learning Outcomes of Information Technology-Assisted Training Courses},
Author = {Schneikart, Gerald and Mayrhofer, Walter},
Journal = {International Journal of Information and Learning Technology},
Year = {2022},
Volume = {39},
Pages = {437-450},
DOI = {http://eric.ed.gov/?id=EJ1360979},
Abstract = {Purpose: The objective of the presented pilot study was to test the applicability of a metric to specifically measure performance improvement via a hands-on workshop about collaborative robotics. Design/methodology/approach: Candidates interested in acquiring basic practical skills in working with a collaborative robot completed a distance learning exercise in preparation for a hands-on training workshop. The candidates executed a test before and after the workshop for recording the parameters compiled in the tested performance index (PI). Findings: The results reflected the potential of the tested PI for applications in detecting improvement in practical skill acquisition and revealed potential opportunities for integrating additional performance factors. Research limitations/implications: The low number of candidates available limited in-depth analyses of the learning outcomes. Practical implications: The study outcomes provide the basis for follow-up projects with larger cohorts of candidates and control groups in order to expedite the development of technology-assisted performance measurements. Social implications: The study contributes to research on performance improvement and prediction of learning outcomes, which is imperative to this emerging field in learning analytics. Originality/value: The development of the presented PI addresses a scientific gap in learning analytics, i.e. the objective measurement of performance improvement and prediction along skill-intensive training courses. This paper presents an improved version of the PI, which was published at the 12th Conference on Learning Factories, Singapore, April 2022.},
Keywords = {Measurement Techniques, Robotics, Workshops, Technology Uses in Education, Distance Education, Training, Performance, Skill Development, Performance Tests, Programming, Program Effectiveness},
ISSN = { ISSN-2056-4880},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED607840,
Title = {Deep Embeddings of Contextual Assessment Data for Improving Performance Prediction},
Author = {Clavié, Benjamin and Gal, Kobi},
Journal = {International Educational Data Mining Society},
Year = {2020},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED607840},
Abstract = {We introduce DeepPerfEmb, or DPE, a new deep-learning model that captures dense representations of students' online behaviour and meta-data about students and educational content. The model uses these representations to predict student performance. We evaluate DPE on standard datasets from the literature, showing superior performance to the state-of-the-art systems in predicting whether or not students will answer a given question correctly. In particular, DPE is unaffected by the cold-start problem which arises when new students come to the system with little to no data available. We also show strong performance of the model when removing students' histories altogether, relying in part on contextual information about the questions. This strong performance without any information about the learners' histories demonstrates the high potential of using deep embedded representations of contextual information in educational data mining. [For the full proceedings, see ED607784.]},
Keywords = {Student Behavior, Electronic Learning, Metadata, Prediction, Performance, Intelligent Tutoring Systems, Student Evaluation, Data Collection, Models, Context Effect, Data Analysis, Artificial Intelligence},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1258927,
Title = {Evaluating the Impact of Prior Required Scaffolding Items on the Improvement of Student Performance Prediction},
Author = {Asselman, Amal and Khaldi, Mohamed and Aammou, Souhaib},
Journal = {Education and Information Technologies},
Year = {2020},
Volume = {25},
Pages = {3227-3249},
DOI = {http://eric.ed.gov/?id=EJ1258927},
Abstract = {Recently, tracking student behavior has become a very important phase for constructing adaptive educational systems. Several researchers have developed various methods based on machine learning for better tracing students' knowledge. Most of these methods have shown an effective estimation of student features and an accurate prediction of future performance. However, these methods recognized certain limitations since they use only the correctness of prior student responses to make predictions without paying attention to many other important student behaviors. In addition, researchers have only considered scaffolding items as a pure method of learning without having analyzed student performance at the time of answering these items. Our purpose in this article is to conduct an experiment that aims to evaluate how best to use data about the prior required scaffolding items to predict future student performance. For this reason, we proposed two separate models, namely, the first one identifies whether a student has previously required to use scaffolding items prior main question or has immediately answered it without requiring assistance. For the second model, as an improvement of model 1, our objective is to improve the student's performance under the constraint of answering scaffolding items. The performance of our two models is evaluated against the original Performance Factors Analysis algorithm to mark differences. The results show that the two proposed models provide a positive improvement in predicting the future performance of students. Moreover, our second model can reliably increase the predictive accuracy.},
Keywords = {Scaffolding (Teaching Technique), Predictor Variables, Student Behavior, Academic Achievement, Artificial Intelligence, Man Machine Systems},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Evaluative},
Language = {English},
}


@article{EJ1348671,
Title = {Framework for Automatically Suggesting Remedial Actions to Help Students at Risk Based on Explainable ML and Rule-Based Models},
Author = {Albreiki, Balqis},
Journal = {International Journal of Educational Technology in Higher Education},
Year = {2022},
Volume = {19},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1348671},
Abstract = {Higher education institutions often struggle with increased dropout rates, academic underachievement, and delayed graduations. One way in which these challenges can potentially be addressed is by better leveraging the student data stored in institutional databases and online learning platforms to predict students' academic performance early using advanced computational techniques. Several research efforts have focused on developing systems that can predict student performance. However, there is a need for a solution that can predict student performance and identify the factors that directly influence it. This paper aims to develop a model that accurately identifies students who are at risk of low performance, while also delineating the factors that contribute to this phenomenon. The model employs explainable machine learning (ML) techniques to delineate the factors that are associated with low performance and integrates rule-based model risk flags with the developed prediction system to improve the accuracy of performance predictions. This helps low-performing students to improve their academic metrics by implementing remedial actions that address the factors of concern. The model suggests proper remedial actions by mapping the students' performance in each identified checkpoint with the course learning outcomes (CLOs) and topics taught in the course. The list of possible actions is mapped to this checkpoint. The developed model can accurately distinguish students at risk (total grade < 70%) from students with good performance. The Area under the ROC Curve (AUC ROC) of binary classification model fed with four checkpoints reached 1.0. Proposed framework may aid the student to perform better, increase the institution's effectiveness and improve their reputations and rankings.},
Keywords = {Automation, Remedial Instruction, At Risk Students, College Students, Artificial Intelligence, Low Achievement, Academic Achievement},
ISSN = { EISSN-2365-9440},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1249916,
Title = {Predicting Students' Academic Performance by Using Educational Big Data and Learning Analytics: Evaluation of Classification Methods and Learning Logs},
Author = {Huang, Anna Y. Q. and Lu, Owen H. T. and Huang, Jeff C. H. and Yin, C. J. and Yang, Stephen J. H.},
Journal = {Interactive Learning Environments},
Year = {2020},
Volume = {28},
Pages = {206-230},
DOI = {http://eric.ed.gov/?id=EJ1249916},
Abstract = {In order to enhance the experience of learning, many educators applied learning analytics in a classroom, the major principle of learning analytics is targeting at-risk student and given timely intervention according to the results of student behavior analysis. However, when researchers applied machine learning to train a risk identifying model, the reason which affected the performance of the model was overlooked. This study collected seven datasets within three universities located in Taiwan and Japan and listed performance metrics of risk identification model after fed data into eight classification methods. U1, U2, and U3 were used to denote the three universities, which have three, two, and two cases of datasets (learning logs), respectively. According to the results of this study, the factors influencing the predictive performance of classification methods are the number of significant features, the number of categories of significant features, and Spearman correlation coefficient values. In U1 dataset case 1.3 and U2 dataset case 2.2, the numbers of significant features, numbers of categories of significant features, and Spearman correlation coefficient values for significant features were all relatively high, which is the main reason why these datasets were able to perform classification with high predictive ability.},
Keywords = {Academic Achievement, Data Use, Learning Analytics, Classification, Foreign Countries, At Risk Students, College Students, Electronic Learning, Prediction, Online Courses, Identification, Reading, Student Behavior},
ISSN = { ISSN-1049-4820},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED630853,
Title = {Generalizing Predictive Models of Reading Ability in Adaptive Mathematics Software},
Author = {Husni Almoubayyed and Stephen E. Fancsali and Steve Ritter},
Journal = {International Educational Data Mining Society},
Year = {2023},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED630853},
Abstract = {Recent research seeks to develop more comprehensive learner models for adaptive learning software. For example, models of reading comprehension built using data from students' use of adaptive instructional software for mathematics have recently been developed. These models aim to deliver experiences that consider factors related to learning beyond performance in the target domain for instruction. We investigate the extent to which generalization is possible for a recently developed predictive model that seeks to infer students' reading comprehension ability (as measured by end-of-year standardized test scores) using an introductory learning experience in Carnegie Learning's MATHia intelligent tutoring system for mathematics. Building on a model learned on data from middle school students in a single school district in a mid-western U.S. state, using that state's end-of-year English Language Arts (ELA) standardized test score as an outcome, we consider data from a school district in a south-eastern U.S. state as well as that state's end-of-year ELA standardized test outcome. Generalization is explored by considering prediction performance when training and testing models on data from each of the individual school districts (and for their respective state's test outcomes) as well as pooling data from both districts together. We conclude with discussion of investigations of some algorithmic fairness characteristics of the learned models. The results suggest that a model trained on data from the smaller of the two school districts considered may achieve greater fairness in its predictions over models trained on data from the other district or both districts, despite broad, overall similarities in some demographic characteristics of the two school districts. This raises interesting questions for future research on generalizing these kinds of models as well as on ensuring algorithmic fairness of resulting models for use in real-world adaptive systems for learning. [For the complete proceedings, see ED630829.]},
Keywords = {Prediction, Models, Reading Ability, Computer Software, Mathematics Instruction, Intelligent Tutoring Systems, Middle School Students, Language Arts, Academic Achievement, Standardized Tests, Grade 7, Reading Comprehension},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1416203,
Title = {ML-Based Intelligent Real-Time Feedback System for Blended Classroom},
Author = {Ujjwal Biswas and Samit Bhattacharya},
Journal = {Education and Information Technologies},
Year = {2024},
Volume = {29},
Pages = {3923-3951},
DOI = {http://eric.ed.gov/?id=EJ1416203},
Abstract = {The application of machine learning (ML) has grown and is now used to enhance learning outcomes. In blended classroom settings, ML, emerging smartphones and wearable technologies are commonly used to improve teaching and learning. The combination of these advanced technologies and ML plays a crucial role in enhancing real-time feedback quality. However, there are abundant scopes of improvement and strong need for further careful investigations in this area. We propose an "ML-based intelligent real-time feedback system" to address current research challenges for blended classrooms. The proposed system provides real-time feedback to students and teachers. We build an Android application for our intelligent feedback interfaces. The user interfaces use students' academic performance prediction models with real-time states and dynamic feedback timings based on historic feedback statistics. In addition, the feedback scheduling algorithms, choices of peripheral devices for real-time feedback, and feedback modalities to optimize fatigue make our system interfaces intelligent and novel. The end users well-received the intelligent features and technology of the proposed system. Our empirical findings indicate that unique design elements, such as dynamic timing, choice of peripheral devices, and modalities of real-time feedback, are crucial in integrating the system with blended classes. The intelligent characteristics of the proposed system have been appreciated by a large proportion of the end-users (90.90% of teachers and 84.21% of students) for use in real-time blended classroom environments. The higher comparative system usability scale (SUS) scores with benchmarks show real promise of the system design.},
Keywords = {Artificial Intelligence, Blended Learning, Flipped Classroom, Technology Uses in Education, Handheld Devices, Assistive Technology, Feedback (Response), Computer Oriented Programs, Algorithms, Electronic Learning, Prediction, Models},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Evaluative},
Language = {English},
}


@article{ED633700,
Title = {Bridging the Physical and the Digital Worlds of Learning Analytics in Educational Assessments through Human-AI Collaboration},
Author = {Paredes, Yancy Vance},
Journal = {ProQuest LLC},
Year = {2023},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED633700},
Abstract = {Experience, whether personal or vicarious, plays an influential role in shaping human knowledge. Through these experiences, one develops an understanding of the world, which leads to learning. The process of gaining knowledge in higher education transcends beyond the passive transmission of knowledge from an expert to a novice. Instead, students are encouraged to actively engage in every learning opportunity to achieve mastery in their chosen field. Evaluation of such mastery typically entails using educational assessments that provide objective measures to determine whether the student has mastered what is required of them. With the proliferation of educational technology in the modern classroom, information about students is being collected at an unprecedented rate, covering demographic, performance, and behavioral data. In the absence of analytics expertise, stakeholders may miss out on valuable insights that can guide future instructional interventions, especially in helping students understand their strengths and weaknesses. This dissertation presents Web-Programming Grading Assistant (WebPGA), a homegrown educational technology designed based on various learning sciences principles, which has been used by 6,000+ students. In addition to streamlining and improving the grading process, it encourages students to reflect on their performance. WebPGA integrates learning analytics into educational assessments using students' physical and digital footprints. A series of classroom studies is presented demonstrating the use of learning analytics and assessment data to make students aware of their misconceptions. It aims to develop ways for students to learn from previous mistakes made by themselves or by others. The key findings of this dissertation include the identification of effective strategies of better-performing students, the demonstration of the importance of individualized guidance during the reviewing process, and the likely impact of validating one's understanding of another's experiences. Moreover, the Personalized Recommender of Items to Master and Evaluate (PRIME) framework is introduced. It is a novel and intelligent approach for diagnosing one's domain mastery and providing tailored learning opportunities by allowing students to observe others' mistakes. Thus, this dissertation lays the groundwork for further improvement and inspires better use of available data to improve the quality of educational assessments that will benefit both students and teachers. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
Keywords = {Artificial Intelligence, Learning Analytics, Man Machine Systems, Educational Technology, Grading, Academic Achievement, Student Evaluation, Error Patterns},
Type = {Dissertations/Theses - Doctoral Dissertations},
}


@article{EJ1373555,
Title = {A Learning Analytics Approach Using Social Network Analysis and Binary Classifiers on Virtual Resource Interactions for Learner Performance Prediction},
Author = {Khor, Ean Teng and Dave, Darshan},
Journal = {International Review of Research in Open and Distributed Learning},
Year = {2022},
Volume = {23},
Pages = {123-146},
DOI = {http://eric.ed.gov/?id=EJ1373555},
Abstract = {The COVID-19 pandemic induced a digital transformation of education and inspired both instructors and learners to adopt and leverage technology for learning. This led to online learning becoming an important component of the new normal, with home-based virtual learning an essential aspect for learners on various levels. This, in turn, has caused learners of varying levels to interact more frequently with virtual resources to supplement their learning. Even though virtual learning environments provide basic resources to help monitor the learners' online behaviour, there is room for more insights to be derived concerning individual learner performance. In this study, we propose a framework for visualising learners' online behaviour and use the data obtained to predict whether the learners would clear a course. We explored a variety of binary classifiers from which we achieved an overall accuracy of 80%-85%, thereby indicating the effectiveness of our approach and that learners' online behaviour had a significant effect on their academic performance. Further analysis showed that common patterns of behaviour among learners and/or anomalies in online behaviour could cause incorrect interpretations of a learner's performance, which gave us a better understanding of how our approach could be modified in the future.},
Keywords = {Learning Analytics, Social Networks, Network Analysis, Classification, Algorithms, Educational Technology, Electronic Learning, COVID-19, Pandemics, Visualization, Accuracy, Student Behavior, Academic Achievement, Prediction},
ISSN = { EISSN-1492-3831},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1373134,
Title = {Extracting Topological Features to Identify At-Risk Students Using Machine Learning and Graph Convolutional Network Models},
Author = {Albreiki, Balqis and Habuza, Tetiana and Zaki, Nazar},
Journal = {International Journal of Educational Technology in Higher Education},
Year = {2023},
Volume = {20},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1373134},
Abstract = {Technological advances have significantly affected education, leading to the creation of online learning platforms such as virtual learning environments and massive open online courses. While these platforms offer a variety of features, none of them incorporates a module that accurately predicts students' academic performance and commitment. Consequently, it is crucial to design machine learning (ML) methods that predict student performance and identify at-risk students as early as possible. Graph representations of student data provide new insights into this area. This paper describes a simple but highly accurate technique for converting tabulated data into graphs. We employ distance measures (Euclidean and cosine) to calculate the similarities between students' data and construct a graph. We extract graph topological features (GF) to enhance our data. This allows us to capture structural correlations among the data and gain deeper insights than isolated data analysis. The initial dataset (DS) and GF can be used alone or jointly to improve the predictive power of the ML method. The proposed method is tested on an educational dataset and returns superior results. The use of DS alone is compared with the use of DS+GF in the classification of students into three classes: "failed", "at risk", and "good". The area under the receiver operating characteristic curve (AUC) reaches 0.948 using DS, compared with 0.964 for DS+GF. The accuracy in the case of DS+GF varies from 84.5 to 87.3%. Adding GF improves the performance by 2.019% in terms of AUC and 3.261% in terms of accuracy. Moreover, by incorporating graph topological features through a graph convolutional network (GCN), the prediction performance can be enhanced by 0.5% in terms of accuracy and 0.9% in terms of AUC under the cosine distance matrix. With the Euclidean distance matrix, adding the GCN improves the prediction accuracy by 3.7% and the AUC by 2.4%. By adding graph embedding features to ML models, at-risk students can be identified with 87.4% accuracy and 0.97 AUC. The proposed solution provides a tool for the early detection of at-risk students. This will benefit universities and enhance their prediction performance, improving both effectiveness and reputation.},
Keywords = {Identification, At Risk Students, Artificial Intelligence, Academic Achievement, Graphs, Networks, Prediction, Matrices, Computation, Correlation},
ISSN = { EISSN-2365-9440},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1393853,
Title = {Ontology-Based Group Assessment Analytics Framework for Performances Prediction in Project-Based Collaborative Learning},
Author = {Hadyaoui, Asma and Cheniti-Belcadhi, Lilia},
Journal = {Smart Learning Environments},
Year = {2023},
Volume = {10},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1393853},
Abstract = {This article introduces an ontology-based framework for group assessment analytics that investigates the impact of intra-group interactions on group performance within the context of project-based collaborative learning (PBCL). Additionally, it aims to predict learners' performance based on these interactions. The study involved 312 first-degree students specializing in transportation and technology engineering. The framework collects interaction data from discussion forums and chat rooms, conducts comprehensive data analysis, and constructs prediction models using supervised learning methods. The results unequivocally demonstrate that intra-group interactions significantly affect group performance in PBCL. The prediction model, with an accuracy metric of 0.92 and a final test score of 0.77, supports the credibility of the findings. Notably, the framework utilizes an ePortfolio specifically designed for group assessments, effectively managing both assessment and group data. This framework provides educators with a robust tool to assess group performance, identify areas requiring improvement, and contribute to shaping informed student learning outcomes. Furthermore, it empowers students by enabling them to receive feedback on their collaborative efforts, fostering enhanced interaction skills. These findings carry significant implications for the development and implementation of PBCL environments, offering educators valuable insights for evaluating student progress and making strategic decisions.},
Keywords = {Learning Analytics, Academic Achievement, Prediction, Student Projects, Active Learning, Cooperative Learning, Evaluation Methods, College Students, Group Dynamics},
ISSN = { EISSN-2196-7091},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1324595,
Title = {Predicting At-Risk University Students Based on Their E-Book Reading Behaviours by Using Machine Learning Classifiers},
Author = {Chen, Cheng-Huan and Yang, Stephen J. H. and Weng, Jian-Xuan and Ogata, Hiroaki and Su, Chien-Yuan},
Journal = {Australasian Journal of Educational Technology},
Year = {2021},
Volume = {37},
Pages = {130-144},
DOI = {http://eric.ed.gov/?id=EJ1324595},
Abstract = {Providing early predictions of academic performance is necessary for identifying at-risk students and subsequently providing them with timely intervention for critical factors affecting their academic performance. Although e-book systems are often used to provide students with teaching/learning materials in university courses, seldom has research made the early prediction based on their online reading behaviours by implementing machine learning classifiers. This study explored to what extent university students' academic achievement can be predicted, based on their reading behaviours in an e-book supported course, using the classifiers. It further investigated which of the features extracted from the reading logs influence the predictions. The participants were 100 first-year undergraduates enrolled in a compulsory course at a university in Taiwan. The results suggest that logistic regression supports vector classification, decision trees, and random forests, and neural networks achieved moderate prediction performance with accuracy, precision, and recall metrics. The Bayes classifier identified almost all at-risk students. Additionally, student online reading behaviours affecting the prediction models included: turning pages, going back to previous pages and jumping to other pages, adding/deleting markers, and editing/removing memos. These behaviours were significantly positively correlated to academic achievement and should be encouraged during courses supported by e-books.},
Keywords = {At Risk Students, Electronic Publishing, Student Behavior, Artificial Intelligence, Books, Grade Prediction, College Freshmen, Foreign Countries, Classification},
ISSN = { EISSN-1449-5554},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1380706,
Title = {Investigating Problem Solving on Calculator Items in a Large-Scale Digitally Based Assessment: A Data Mining Approach},
Author = {Jiang, Yang and Cayton-Hodges, Gabrielle A.},
Journal = {Journal for Research in Mathematics Education},
Year = {2023},
Volume = {54},
Pages = {118-140},
DOI = {http://eric.ed.gov/?id=EJ1380706},
Abstract = {This exploratory study investigated the behaviors and content of onscreen calculator usage by a nationally representative sample of eighth-grade students who responded to items from the 2017 National Assessment of Educational Progress mathematics assessment. Meaningful features were generated from the process data to infer whether students spontaneously used calculators for mathematical problem solving, how frequently and when they used them, and the nature of the operations performed on calculators. Sequential pattern mining was applied on sequences of calculator keystrokes to obtain patterns of operations that were representative of students' problem-solving strategies or processes. Results indicated that higher scoring students not only were more likely to use calculators, but also used them in a more goal-driven manner than lower scoring students.},
Keywords = {Grade 8, Problem Solving, Calculators, Mathematics Instruction, Educational Technology, Algebra, Student Behavior, Mathematics Achievement, Middle School Students},
ISSN = { ISSN-0021-8251},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1420671,
Title = {A Systematic Review of AI-Driven Educational Assessment in STEM Education},
Author = {Fan Ouyang and Tuan Anh Dinh and Weiqi Xu},
Journal = {Journal for STEM Education Research},
Year = {2023},
Volume = {6},
Pages = {408-426},
DOI = {http://eric.ed.gov/?id=EJ1420671},
Abstract = {Artificial intelligence (AI), as an emerging technology, has been widely used in STEM education to promote the educational assessment. Although AI-driven educational assessment has the potential to assess students' learning automatically and reduce the workload of instructors, there is still a lack of review works to holistically examine the field of AI-driven educational assessment, especially in the STEM education context. To gain an overview of the application of AI-driven educational assessment in STEM education, this research conducted a systematic review based on 17 empirical research published from 2011 January to 2023 April. Specifically, this review examined the functions, algorithms, and effects of AI applications in STEM educational assessment. The results clarified three main functions of AI-driven educational assessment, namely academic performance assessment, learning status assessment, and instructional quality assessment. Moreover, the systematic review found that both traditional algorithms (e.g., natural language processing, machine learning) and advanced algorithms (e.g., deep learning, neural fuzzy systems) were applied in STEM educational assessment. Furthermore, the educational and technological effects of applying AI-driven educational assessment in STEM education were revealed. Based on the results, this research proposed educational and technological implications to guide the future practice and research of AI-driven educational assessment in STEM education.},
Keywords = {Educational Assessment, Artificial Intelligence, STEM Education, Academic Achievement, Natural Language Processing, Algorithms, Educational Quality, Student Evaluation, Evaluation Methods},
ISSN = { ISSN-2520-8705},
Type = {Journal Articles, Information Analyses},
Language = {English},
}


@article{EJ1298370,
Title = {A Learning Fuzzy Cognitive Map (LFCM) Approach to Predict Student Performance},
Author = {Mansouri, Taha and ZareRavasan, Ahad and Ashrafi, Amir},
Journal = {Journal of Information Technology Education: Research},
Year = {2021},
Volume = {20},
Pages = {221-243},
DOI = {http://eric.ed.gov/?id=EJ1298370},
Abstract = {Aim/Purpose: This research aims to present a brand-new approach for student performance prediction using the Learning Fuzzy Cognitive Map (LFCM) approach. Background: Predicting student academic performance has long been an important research topic in many academic disciplines. Different mathematical models have been employed to predict student performance. Although the available sets of common prediction approaches, such as Artificial Neural Networks (ANN) and regression, work well with large datasets, they face challenges dealing with small sample sizes, limiting their practical applications in real practices. Methodology: Six distinct categories of performance antecedents are adopted here as course characteristics, LMS characteristics, student characteristics, student engagement, student support, and institutional factors, along with measurement items within each category. Furthermore, we assessed the student's overall performance using three items of student satisfaction score, knowledge construction level, and student GPA. We have collected longitudinal data from 30 postgraduates in four subsequent semesters and analyzed data using the Learning Fuzzy Cognitive Map (LFCM) technique. Contribution: This research proposes a brand new approach, Learning Fuzzy Cognitive Map (LFCM), to predict student performance. Using this approach, we identified the most influential determinants of student performance, such as student engagement. Besides, this research depicts a model of interrelations among the student performance determinants. Findings: The results suggest that the model reasonably predicts the incoming sequence when there is a limited sample size. The results also reveal that students' total online time and the regularity of learning interval in LMS have the largest effect on overall performance. The student engagement category also has the highest direct effect on student's overall performance. Recommendations for Practitioners: Academic institutions can use the results and approach developed in this paper to identify students' performance antecedents, predict the performance, and establish action plans to resolve the shortcomings in the long term. Instructors can adjust their learning methods based on the feedback from students in the short run on the operational level. Recommendation for Researchers: Researchers can use the proposed approach in this research to deal with the problems in other domains, such as using LMS for organizational/institutional education. Besides, they can focus on specific dimensions of the proposed model, such as exploring ways to boost student engagement in the learning process. Impact on Society: Our results revealed that students are at the center of the learning process. The degree to which they are dedicated to learning is the most crucial determinant of the learning outcome. Therefore, learners should consider this finding in order the gain value from the learning process. Future Research: As a potential for future works, the proposed approach could be used in other contexts to test its applicability. Future studies could also improve the performance level of the proposed LFMC model by tuning the model's elements.},
Keywords = {Cognitive Mapping, Models, Prediction, Performance Factors, Grade Point Average, Student Satisfaction, Graduate Students, Knowledge Level, Learner Engagement, Learning Analytics, Integrated Learning Systems, Electronic Learning, Time Factors (Learning), Intervals},
ISSN = { ISSN-1547-9714},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1388193,
Title = {Prediction of Student Academic Performance Based on Their Emotional Wellbeing and Interaction on Various E-Learning Platforms},
Author = {Kukkar, Ashima and Mohana, Rajni and Sharma, Aman and Nayyar, Anand},
Journal = {Education and Information Technologies},
Year = {2023},
Volume = {28},
Pages = {9655-9684},
DOI = {http://eric.ed.gov/?id=EJ1388193},
Abstract = {Predicting student performance is crucial in higher education, as it facilitates course selection and the development of appropriate future study plans. The process of supporting the instructors and supervisors in monitoring students in order to upkeep them and combine training programs to get the best outcomes. It decreases the official warning signs and inefficient students' expulsions. Therefore, analysis of students' performance on various academic tests is critical for future skill development. Despite the fact that existing performance prediction systems based on Deep Learning (DL) technologies such as Artificial Neural Networks (ANN), Recurrent Neural Network (RNN) have outperformed Machine Learning (ML) -based systems in the prediction task, there are still a few issues. Ignorance of relevant features, analysis limitations to the existing amount of data points, and ambiguity in student records are only a few of these issues. This research proposes a novel Student Academic Performance Predicting (SAPP) system to address these issues and enhance prediction accuracy. It has a better architecture that uses a combination of 4-layer stacked Long Short Term Memory (LSTM) network, Random Forest (RF), and Gradient Boosting (GB) techniques to predict students' pass or fail outcomes. Additionally, the proposed SAPP system is compared to existing prediction systems using publicly accessible student OULAD dataset with an addition of self-curated emotional dataset. The performance of SAPP system is measured using Accuracy, Precision, F-measure, and Recall parameters. The results of proposed algorithm (LSTM + RF + B) is compared with LSTM + RF, LSTM + B and end to end DL models such as ANN, LSTM, RNN, Convolutional Neural Network (CNN) and most commonly utilized ML models in the literature such as Support Vector Machine (SVM), Decision Tree (DT), Naive Bayes (NB) and RF. The proposed SAPP system gained approximately 96% prediction accuracy that is comparatively higher than existing systems.},
Keywords = {Academic Achievement, Mental Health, Well Being, Interaction, Electronic Learning, Higher Education, College Students, Prediction, Accuracy, Models, Artificial Intelligence, Tests, Outcomes of Education, Algorithms, Bayesian Statistics},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED608007,
Title = {Online Academic Course Performance Prediction Using Relational Graph Convolutional Neural Network},
Author = {Karimi, Hamid and Derr, Tyler and Huang, Jiangtao and Tang, Jiliang},
Journal = {International Educational Data Mining Society},
Year = {2020},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED608007},
Abstract = {Online learning has attracted a large number of participants and is increasingly becoming very popular. However, the completion rates for online learning are notoriously low. Further, unlike traditional education systems, teachers, if any, are unable to comprehensively evaluate the learning gain of each student through the online learning platform. Hence, we need to have an effective framework for evaluating students' performance in online education systems and to predict their expected outcomes and associated early failures. To this end, we introduce Deep Online Performance Evaluation (DOPE), which first models the student course relations in an online system as a knowledge graph, then utilizes an advanced graph neural network to extract course and student embeddings, harnesses a recurrent neural network to encode the system's temporal student behavioral data, and ultimately predicts a student's performance in a given course. Comprehensive experiments on six online courses verify the effectiveness of DOPE across multiple settings against representative baseline methods. Furthermore, we perform ablation feature analysis on the student behavioral features to better understand the inner workings of DOPE. The code and data are available from https://github.com/hamidkarimi/dope. [For the full proceedings, see ED607784.]},
Keywords = {Online Courses, Academic Achievement, Prediction, Teaching Methods, Achievement Gains, Outcomes of Education, Models, Networks, Data Analysis, Evaluation Methods, Student Behavior, Computer Simulation, Computer Mediated Communication, Classification, Online Systems, Open Universities, College Students, Graphs, Visualization},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{ED607784,
Title = {Proceedings of the International Conference on Educational Data Mining (EDM) (13th, Online, July 10-13, 2020)},
Author = {Rafferty, Anna N., Ed. and Whitehill, Jacob, Ed. and Romero, Cristobal, Ed. and Cavalli-Sforza, Violetta, Ed.},
Journal = {International Educational Data Mining Society},
Year = {2020},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED607784},
Abstract = {The 13th iteration of the International Conference on Educational Data Mining (EDM 2020) was originally arranged to take place in Ifrane, Morocco. Due to the SARS-CoV-2 (coronavirus) epidemic, EDM 2020, as well as most other academic conferences in 2020, had to be changed to a purely online format. To facilitate efficient transmission of presentations all paper presenters pre-recorded their presentation as a video and then hosted it on YouTube with closed-captioning (CC). The official theme of this year's conference is Improving Learning Outcomes for All Learners. The theme comprises two parts: (1) Identifying actionable learning or teaching strategies that can be used to "improve" learning outcomes, not just predict them; (2) Using EDM to promote more "equitable" learning across diverse groups of learners, and to benefit underserved communities in particular. This year's conference features three invited talks: Alina von Davier, Chief Officer at ACTNext; Abelardo Pardo, Professor and Dean of Programs (Engineering), at UniSA STEM, University of South Australia; and Kobi Gal, Associate Professor at the Department of Software and Information Systems Engineering at Ben-Gurion University of the Negev, and Reader at the School of Informatics at the University of Edinburgh.},
Keywords = {Educational Improvement, Teaching Methods, Information Retrieval, Data Processing, Data Analysis, Equal Education, Student Diversity, Cooperative Learning, Online Courses, Demography, Transformative Learning, Blended Learning, Learning Strategies, Large Group Instruction, Artificial Intelligence, Educational Technology, Privacy, Learner Engagement, Student Motivation, Programming, Models, Game Based Learning, Competence, Problem Solving, Information Sources, Critical Theory, At Risk Students, Elementary Secondary Education, Spatial Ability, Visualization, Intervention, Student Characteristics, Automation, Remedial Reading, Handheld Devices, Video Technology, Item Response Theory, Reinforcement, Student Behavior, Prediction, Success, College Students, Data Collection, Masters Programs, Reaction Time, Reading Comprehension, College Admission, Essays, Peer Teaching, Performance, Teamwork, Student Projects, Inquiry, Electronic Publishing, Textbooks, Tests, Ethics, Legal Responsibility, Higher Education, Measurement Techniques, Reading Achievement, Grade 9, Video Games, Peer Evaluation, Secondary Schools, Computer Science Education, Physics, Feedback (Response), Semitic Languages, Technical Writing, Telecommunications, Personal Autonomy, Computer Software, Plagiarism, Curriculum, Collaborative Writing, Dropouts, Educational Assessment, Gender Differences, Difficulty Level, Social Media, Mental Health, Innovation, Student Role, Eye Movements, Foreign Countries, Bayesian Statistics, Scores, Distance Education, Student Attitudes, Scoring, Natural Language Processing, Middle School Students, Social Networks, Employment Qualifications, Intelligent Tutoring Systems, Anxiety, Second Languages, Cues, Visual Aids},
Type = {Collected Works - Proceedings},
}


@article{EJ1253324,
Title = {Predicting Student Final Performance Using Artificial Neural Networks in Online Learning Environments},
Author = {Aydogdu, Seyhmus},
Journal = {Education and Information Technologies},
Year = {2020},
Volume = {25},
Pages = {1913-1927},
DOI = {http://eric.ed.gov/?id=EJ1253324},
Abstract = {Prediction of student performance is one of the most important subjects of educational data mining. Artificial neural networks are seen to be an effective tool in predicting student performance in e-learning environments. In the studies carried out with artificial neural networks, performance predictions based on student scores are generally made, but students' use of learning management system is not focused. In this study, performances of 3518 university students, who studying and actively participating in a learning management system, were tried to be predicted by artificial neural networks in terms of gender, content score, time spent on the content, number of entries to content, homework score, number of attendance to live sessions, total time spent in live sessions, number of attendance to archived courses and total time spent in archived courses variables. Since it is difficult to interpret how much input variables in artificial neural networks contribute to predicting output variables, these networks are called black boxes. Also, in this study the amount of contribution of input variables on the prediction of output variable was also examined. The artificial neural network created as a result of the study makes a prediction with an accuracy of 80.47%. Finally, it was found that the variables of number of attendance to the live classes, the number of attendance to archived courses and the time spent in the content contributed most to the prediction of the output variable.},
Keywords = {Prediction, Academic Achievement, Electronic Learning, Artificial Intelligence, Homework, Scores, Gender Differences, Management Systems, College Students, Time Factors (Learning), Attendance, Course Content, Data Analysis, Teaching Methods},
ISSN = { ISSN-1360-2357},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1305077,
Title = {Enhancing Data Pipelines for Forecasting Student Performance: Integrating Feature Selection with Cross-Validation},
Author = {Bertolini, Roberto and Finch, Stephen J. and Nehm, Ross H.},
Journal = {International Journal of Educational Technology in Higher Education},
Year = {2021},
Volume = {18},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1305077},
Abstract = {Educators seek to harness knowledge from educational corpora to improve student performance outcomes. Although prior studies have compared the efficacy of data mining methods (DMMs) in pipelines for forecasting student success, less work has focused on identifying a set of relevant features prior to model development and quantifying the stability of feature selection techniques. Pinpointing a subset of pertinent features can (1) reduce the number of variables that need to be managed by stakeholders, (2) make "black-box" algorithms more interpretable, and (3) provide greater guidance for faculty to implement targeted interventions. To that end, we introduce a methodology integrating feature selection with cross-validation and rank each feature on subsets of the training corpus. This modified pipeline was applied to forecast the performance of 3225 students in a baccalaureate science course using a set of 57 features, four DMMs, and four filter feature selection techniques. Correlation Attribute Evaluation (CAE) and Fisher's Scoring Algorithm (FSA) achieved significantly higher Area Under the Curve (AUC) values for logistic regression (LR) and elastic net regression (GLMNET), compared to when this pipeline step was omitted. Relief Attribute Evaluation (RAE) was highly unstable and produced models with the poorest prediction performance. Borda's method identified grade point average, number of credits taken, and performance on concept inventory assessments as the primary factors impacting predictions of student performance. We discuss the benefits of this approach when developing data pipelines for predictive modeling in undergraduate settings that are more interpretable and actionable for faculty and stakeholders.},
Keywords = {Data Processing, Prediction, Validity, Undergraduate Students, College Science, Biology, Introductory Courses, Grade Point Average, College Credits, Measures (Individuals)},
ISSN = { EISSN-2365-9440},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1407341,
Title = {Personalized Intervention Based on the Early Prediction of At-Risk Students to Improve Their Learning Performance},
Author = {Anna Y. Q. Huang and Jei Wei Chang and Albert C. M. Yang and Hiroaki Ogata and Shun Ting Li and Ruo Xuan Yen and Stephen J. H. Yang},
Journal = {Educational Technology & Society},
Year = {2023},
Volume = {26},
Pages = {69-89},
DOI = {http://eric.ed.gov/?id=EJ1407341},
Abstract = {To improve students' learning performance through review learning activities, we developed a personalized intervention tutoring approach that leverages learning analysis based on artificial intelligence. The proposed intervention first uses text-processing artificial intelligence technologies, namely bidirectional encoder representations from transformers and generative pretrained transformer-2, to automatically generate Python programming remedial materials; subsequently, learning performance prediction models constructed using various machine learning methods are used to determine students' learning type, enabling the automatic generation of personalized remedial materials. The participants in this study were 78 students from a university in northern Taiwan enrolled in an 8-week Python course. Students in the experimental (n = 36) and control (n = 42) groups engaged in the same programming learning activities during the first 5 weeks of the course, and they completed a pretest of programming knowledge in Week 6. For the review activity in Week 7, the 36 students in the experimental group received personalized intervention, whereas those in the control group received traditional class tutoring. We examined the effect of the self-regulated learning and personalized intervention on the learning performance of students. Compared with the traditional class tutoring, the personalized intervention review activity not only helped students obtain higher learning performance but also prompted greater improvements in the following learning strategies: rehearsal, critical thinking, metacognitive self-regulation, effort regulation, and peer learning. We also observed that students' rehearsal and help-seeking learning strategies indirectly affected learning performance through students' note-taking in the provided e-book.},
Keywords = {Academic Achievement, Tutoring, Artificial Intelligence, Individualized Instruction, Computer Software, Technology Uses in Education, Man Machine Systems, Cognitive Style, Remedial Instruction, College Students, Universities, Foreign Countries, At Risk Students, Identification, Intervention, Natural Language Processing, Electronic Learning, Programming Languages},
ISSN = { ISSN-1176-3647},
Type = {Journal Articles, Reports - Research, Tests/Questionnaires},
}


@article{ED615654,
Title = {Student-Centric Model of Login Patterns: A Case Study with Learning Management Systems},
Author = {Mandalapu, Varun and Chen, Lujie Karen and Chen, Zhiyuan and Gong, Jiaqi},
Journal = {International Educational Data Mining Society},
Year = {2021},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED615654},
Abstract = {With the increasing adoption of Learning Management Systems (LMS) in colleges and universities, research in exploring the interaction data captured by these systems is promising in developing a better learning environment and improving teaching practice. Most of these research efforts focused on course-level variables to predict student performance in specific courses. However, these research findings for individual courses are limited to develop beneficial pedagogical interventions at the student level because students often have multiple courses simultaneously. This paper argues that student-centric models will provide systematic insights into students' learning behavior to develop effective teaching practice. This study analyzed 1651 undergraduate student's data collected in Fall 2019 from computer science and information systems departments at a US university that actively uses Blackboard as an LMS. The experimental results demonstrated the prediction performance of student-centric models and explained the influence of various predictors related to login volumes, login regularity, login chronotypes, and demographics on predictive models. Our findings show that student prior performance and normalized student login volume across courses significantly impact student performance models. We also observe that regularity in student logins has a significant influence on low performing students and students from minority races. Based on these findings, the implications were discussed to develop potential teaching practices for these students. [For the full proceedings, see ED615472.]},
Keywords = {Integrated Learning Systems, Interaction, Undergraduate Students, Minority Group Students, College Transfer Students, Student Characteristics, Grade Point Average, Racial Differences, Ethnicity, Behavior Patterns, Intervals, Learning Analytics, Performance Factors, Predictor Variables, Models, Public Colleges},
Type = {Reports - Research, Speeches/Meeting Papers},
}


@article{EJ1240438,
Title = {Modified Fuzzy Rule-Based Classification System for Early Warning of Student Learning},
Author = {Zhao, Qun and Wang, Jin-Long and Pao, Tsang-Long and Wang, Li-Yu},
Journal = {Journal of Educational Technology Systems},
Year = {2020},
Volume = {48},
Pages = {385-406},
DOI = {http://eric.ed.gov/?id=EJ1240438},
Abstract = {This study uses the log data from Moodle learning management system for predicting student learning performance in the first third of a semester. Since the quality of the data has great influence on the accuracy of machine learning, five major data transmission methods are used to enhance data quality of log file in the data preprocessing stage. Furthermore, the modified FRBCS-CHI (fuzzy rule-based classification system using Chi's technique) algorithm, based on the weighted consequence, is proposed to improve the prediction accuracy of classification. Thereafter, the confusion matrix with two dimensions is employed to illustrate the prediction results, such as false positives, false negatives, true positives, and true negatives, which are further used to produce the parameters of prediction performance, including the precision rate, the recall rate, and the F-measure. From the results of experiment, the proposed modified FRBCS-CHI method will have higher prediction accuracy than the original FRBCS-CHI method.},
Keywords = {Classification, Learning, Accuracy, Prediction, Data Use, Integrated Learning Systems, Student Evaluation, Learning Analytics, College Students},
ISSN = { ISSN-0047-2395},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED607904,
Title = {Evaluating Sources of Course Information and Models of Representation on a Variety of Institutional Prediction Tasks},
Author = {Jiang, Weijie and Pardos, Zachary A.},
Journal = {International Educational Data Mining Society},
Year = {2020},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED607904},
Abstract = {Data mining of course enrollment and course description records has soared as institutions of higher education begin tapping into the value of these data for academic and internal research purposes. This has led to a more than doubling of papers on course prediction tasks every year. The papers often center around a single prediction task and introduce a single novel modeling approach utilizing one or two data sources. In this paper, we provide the most comprehensive evaluation to date of data sources, models, and their performance on downstream prediction tasks. We separately incorporate syllabus, catalog description, and enrollment history data to represent courses using graph embedding, course2vec (i.e., skip-gram), and classic bag-of-words models. We evaluate these representations on the tasks of predicting course prerequisites, credit equivalencies, student next semester enrollments, and student course grades. Most notably, our results show that syllabi bag-of-words representations performed better than course descriptions in predicting prerequisite relationships, though enrollment-based graph embeddings performed substantially better still. Course descriptions provided the highest single representation accuracy in predicting course similarity, with descriptions, syllabi, and course2vec combined representations providing the highest ensembled accuracy on this task. [For the full proceedings, see ED607784.]},
Keywords = {Course Descriptions, Models, Prediction, Course Selection (Students), Enrollment Trends, Data Analysis, Data Use, Integrated Learning Systems, Enrollment},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1383391,
Title = {Using Problem Similarity-and Order-Based Weighting to Model Learner Performance in Introductory Computer Science Problems},
Author = {Zhang, Yingbin and Pinto, Juan D. and Fan, Aysa Xuemo and Paquette, Luc},
Journal = {Journal of Educational Data Mining},
Year = {2023},
Volume = {15},
Pages = {63-99},
DOI = {http://eric.ed.gov/?id=EJ1383391},
Abstract = {The second CSEDM data challenge aimed at finding innovative methods to use students' programming traces to model their learning. The main challenge of this task is how to decide which past problems are relevant for predicting performance on a future problem. This paper proposes a set of weighting schemes to address this challenge. Specifically, students' behaviors and performance on past problems were weighted in predicting performance on future problems. The weight of a past problem was proportional to its similarity with the future problem. Problem similarity was quantified in terms of source code, problem prompts, and struggling patterns. In addition, we considered another weighting scheme where past problems were weighted by the order in which students attempted them. Prior studies have used problem similarity and order information in learner modeling, but the proposed weighting schemes are more flexible in capturing problem similarity on various problem properties and weighting various behaviors and performance information on past problems. We systematically investigate the utility of the weighting schemes on performance prediction through two analyses. The first analysis found that the weighting schemes based on source code similarity, struggling pattern similarity, and problem order improved the prediction performance, but the weighting scheme based on problem prompts did not. The second analysis found that the weighting scheme allows a simple and interpretable model, such as logistic regression, to have performance comparable to state-of-the-art deep-learning models. We discussed the implications of the weighting schemes for learner modeling and suggested directions for further improvement.},
Keywords = {Problem Solving, Introductory Courses, Computer Science Education, Programming, Models, Prediction, Performance, Decision Making, Regression (Statistics), Measurement Techniques},
ISSN = { EISSN-2157-2100},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{EJ1273917,
Title = {When Is Deep Learning the Best Approach to Knowledge Tracing?},
Author = {Gervet, Theophile and Koedinger, Ken and Schneider, Jeff and Mitchell, Tom},
Journal = {Journal of Educational Data Mining},
Year = {2020},
Volume = {12},
Pages = {31-54},
DOI = {http://eric.ed.gov/?id=EJ1273917},
Abstract = {Intelligent tutoring systems (ITSs) teach skills using learning-by-doing principles and provide learners with individualized feedback and materials adapted to their level of understanding. Given a learner's history of past interactions with an ITS, a learner performance model estimates the current state of a learner's knowledge and predicts her future performance. The advent of increasingly large scale datasets has turned deep learning models for learner performance prediction into competitive alternatives to classical Markov process and logistic regression models. In an extensive empirical comparison on nine real-world datasets, we ask which approach makes the most accurate predictions and in what conditions. Logistic regression--with the right set of features--leads on datasets of moderate size or containing or containing a very large number of interactions per student, whereas Deep Knowledge Tracing leads on datasets of large size or where precise temporal information matters most. Markov process methods, like Bayesian Knowledge Tracing, lag behind other approaches. We follow this analysis with ablation studies to determine what components of leading algorithms explain their performance and a discussion of model calibration (reliability), which is crucial for downstream applications of learner performance prediction models.},
Keywords = {Learning Processes, Intelligent Tutoring Systems, Feedback (Response), Knowledge Level, Prediction, Markov Processes, Comparative Analysis, Data Analysis, Bayesian Statistics, Academic Achievement},
ISSN = { EISSN-2157-2100},
Type = {Journal Articles, Reports - Research},
Language = {English},
}


@article{ED615578,
Title = {Exploring the Importance of Factors Contributing to Dropouts in Higher Education over Time},
Author = {Tanvir, Hasan and Chounta, Irene-Angelica},
Journal = {International Educational Data Mining Society},
Year = {2021},
Volume = {},
Pages = {},
DOI = {http://eric.ed.gov/?id=ED615578},
Abstract = {The aim of this work is to provide data-driven insights regarding the factors behind dropouts in Higher Education and their impact over time. To this end, we analyzed students' data collected by a Higher Education Institute over the last 11 years and we explored how socio-economic and academic changes may have impacted student dropouts and how these changes may have been reflected or captured by students' data. To analyze the data, we engineered features that may predict student dropouts on three dimensions: academic background, students' performance and students' effort. Then we carried out a correlation analysis to investigate the potential relationship between these features and dropouts, we performed a multivariate analysis of variance (MANOVA) to investigate whether the engineered features change significantly among student cohorts with different admission year and, finally, we carried out a regression analysis to confirm that the engineered features' impact on predicting dropouts changes over the years. The results suggest that the importance of features regarding the academic background of students (such as the students' prior experience with the academic institution), and the effort students make (for example, the number of days students spend on academic leave) may change over time. On the contrary, performance-based features (such as credit points and grades) do interact with time suggesting that performance measures are stable predictors of dropouts over time. On the basis of the findings, we argue that the performance of prediction models for assessing students at risk of dropping out of their studies can be affected by the age of data and we outline the possibility of including a forgetting factor for non-recent data in order to leverage their impact on prediction performance. [For the full proceedings, see ED615472.]},
Keywords = {Dropouts, College Students, Predictor Variables, Socioeconomic Status, Student Characteristics, Academic Achievement, Student Motivation, Multivariate Analysis, Foreign Countries},
Type = {Speeches/Meeting Papers, Reports - Research},
}


@article{EJ1288550,
Title = {Using Process Data to Understand Problem-Solving Strategies and Processes for Drag-and-Drop Items in a Large-Scale Mathematics Assessment},
Author = {Jiang, Yang and Gong, Tao and Saldivia, Luis E. and Cayton-Hodges, Gabrielle and Agard, Christopher},
Journal = {Large-scale Assessments in Education},
Year = {2021},
Volume = {9},
Pages = {},
DOI = {http://eric.ed.gov/?id=EJ1288550},
Abstract = {In 2017, the mathematics assessments that are part of the National Assessment of Educational Progress (NAEP) program underwent a transformation shifting the administration from paper-and-pencil formats to digitally-based assessments (DBA). This shift introduced new interactive item types that bring rich process data and tremendous opportunities to study the cognitive and behavioral processes that underlie test-takers' performances in ways that are not otherwise possible with the response data alone. In this exploratory study, we investigated the problem-solving processes and strategies applied by the nation's fourth and eighth graders by analyzing the process data collected during their interactions with two technology-enhanced drag-and-drop items (one item for each grade) included in the first digital operational administration of the NAEP's mathematics assessments. Results from this research revealed how test-takers who achieved different levels of accuracy on the items engaged in various cognitive and metacognitive processes (e.g., in terms of their time allocation, answer change behaviors, and problem-solving strategies), providing insights into the common mathematical misconceptions that fourth- and eighth-grade students held and the steps where they may have struggled during their solution process. Implications of the findings for educational assessment design and limitations of this research are also discussed.},
Keywords = {Data Use, Learning Analytics, Test Items, Measurement, Mathematics Tests, Computer Assisted Testing, Problem Solving, Misconceptions, National Competency Tests, Grade 4, Grade 8},
ISSN = { EISSN-2196-0739},
Type = {Journal Articles, Reports - Research},
Language = {English},
}
