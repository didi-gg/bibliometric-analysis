@article{EMBARAK2024151,
title = {Automated AI-driven System for Early Detection of At-risk Students},
journal = {Procedia Computer Science},
volume = {231},
pages = {151-160},
year = {2024},
note = {14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 13th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (EUSPN/ICTH 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.12.187},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923021993},
author = {Ossama H. Embarak and Shatha Hawarna},
keywords = {An automated system using XAI, At-risk students, Student risk detection, Personalized interventions, Proactive measures, Continuous monitoring, Multi-modal approach, Feature selection},
abstract = {This study presents the development of a novel automated system, Rapid Analysis and Detection of At-risk students with Artificial intelligence-based Response (RADAR), that utilizes explainable artificial intelligence (XAI) to identify students who are at risk of falling behind or dropping out of school. The system integrates various features, including learners' personality, previous academic performance, current academic concepts progress, and soft skills. Machine learning algorithms are utilized to analyze the combination of data and identify patterns that predict a student's likelihood of falling behind. The proposed RADAR system employs a multi-modal approach, considering the learner's features. The system is trained on a dataset of students from a school district, where the data is collected and preprocessed accordingly. The feature selection algorithm is applied to identify the most relevant features that can accurately predict students at-risk of falling behind or dropping out. The pilot study establishes the framework of the system and examines the implementation implications. The results of this study indicate that the RADAR system achieves high accuracy in identifying at-risk students. Furthermore, the system effectively employs the identified features to predict students' performance in a continuous manner, enabling advisors, administrators, and students to take proactive measures to maintain high academic progress levels. The system is designed to provide an automated and continuous monitoring of the students' performance, and to notify the relevant parties in case of any deviations. The proposed system represents an innovative approach to using XAI for the detection and support of at-risk students, enabling educators to take timely actions. The results of this study demonstrate the potential of the RADAR system to improve the support and guidance provided to at-risk students, and to ultimately improve their academic outcomes.}
}
@article{ZACHARIS201544,
title = {A multivariate approach to predicting student outcomes in web-enabled blended learning courses},
journal = {The Internet and Higher Education},
volume = {27},
pages = {44-53},
year = {2015},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2015.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1096751615000391},
author = {Nick Z. Zacharis},
keywords = {Learning analytics, Blended learning},
abstract = {This study aimed to develop a practical model for predicting students at risk of performing poorly in blended learning courses. Previous research suggests that analyzing usage data stored in the log files of modern Learning Management Systems (LMSs) would allow teachers to develop timely, evidence-based interventions to support at risk or struggling students. The analysis of students' tracking data from a Moodle LMS-supported blended learning course was the focus of this research in an effort to identify significant correlations between different online activities and course grade. Out of 29 LMS usage variables, 14 were found to be significant and were input in a stepwise multivariate regression which revealed that only four variables – Reading and posting messages, Content creation contribution, Quiz efforts and Number of files viewed – predicted 52% of the variance in the final student grade.}
}
@article{SHUKOR20144844,
title = {A Predictive Model to Evaluate Students’ Cognitive Engagement in Online Learning},
journal = {Procedia - Social and Behavioral Sciences},
volume = {116},
pages = {4844-4853},
year = {2014},
note = {5th World Conference on Educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.01.1036},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814010532},
author = {Nurbiha A. Shukor and Zaidatun Tasir and Henny {Van der Meijden} and Jamalludin Harun},
keywords = {Online learning, cognitve engagement, content analysis, data mining},
abstract = {The expanding usage of online learning at all levels of education has drawn attention to the quality of online learning. In this study, online learning quality is evaluated through students’ cognitive engagement which is reflected in their online written messages in discussions and their online participation. This study proposes the use of two types of data: students’ participation, and written messages. Both types of data was collected and analyzed using the data mining technique to produce a predictive model that illustrates students’ pathways while engaging in online learning cognitively. The findings of this study indicate that from 22 variables, only two were significant for students’ online cognitive engagement; sharing information and posting high- level messages. The two variables led to the formation of three different pathways in the students’ predictive model.}
}
@article{MATHRANI2021100060,
title = {Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics},
journal = {Computers and Education Open},
volume = {2},
pages = {100060},
year = {2021},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2021.100060},
url = {https://www.sciencedirect.com/science/article/pii/S2666557321000318},
author = {Anuradha Mathrani and Teo Susnjak and Gomathy Ramaswami and Andre Barczak},
keywords = {Learning analytics, Generalizability, Interpretability, Feature extraction, Transparency, Ethics protocol},
abstract = {Educational institutions need to formulate a well-established data-driven plan to get long-term value from their learning analytics (LA) strategy. By tracking learners’ digital traces and measuring learners’ performance, institutions can discern consequential learning trends via use of predictive models to enhance their instructional services. However, questions remain on how the proposed LA system is suitable, meaningful, and justifiable. In this concept paper, we examine generalizability and transparency of the internals of predictive models, alongside the ethical challenges in using learners’ data for building predictive capabilities. Model generalizability or transferability is hindered by inadequate feature representation, small and imbalanced datasets, concept drift, and contextually un-related domains. Additional challenges relate to trustworthiness and social acceptance of these models since algorithmic-driven models are difficult to interpret by themselves. Further, ethical dilemmas are faced in engaging with learners’ data while developing and deploying LA systems at an institutional level. We propose methodologies for apprehending these challenges by establishing efforts for managing transferability and transparency, and further assessing the ethical standing on justifiable use of the LA strategy. This study showcases underlying relationships that exist between constructs pertaining to learners’ data and the predictive model. We suggest the use of appropriate evaluation techniques and setting up research ethics protocols, since without proper controls in place, the model outcome would not be portable, transferable, trustworthy, or admissible as a responsible outcome. This concept paper has theoretical and practical implications for future inquiry in the burgeoning field of learning analytics.}
}
@article{HOWARD201866,
title = {Contrasting prediction methods for early warning systems at undergraduate level},
journal = {The Internet and Higher Education},
volume = {37},
pages = {66-75},
year = {2018},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2018.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1096751617303974},
author = {Emma Howard and Maria Meehan and Andrew Parnell},
keywords = {Learning analytics, Early warning systems, Undergraduate education, Prediction modelling},
abstract = {Recent studies have provided evidence in favour of adopting early warning systems as a means of identifying at-risk students. Our study examines eight prediction methods, and investigates the optimal time in a course to apply such a system. We present findings from a statistics university course which has weekly continuous assessment and a large proportion of resources on the Learning Management System Blackboard. We identify weeks 5–6 (half way through the semester) as an optimal time to implement an early warning system, as it allows time for the students to make changes to their study patterns while retaining reasonable prediction accuracy. Using detailed variables, clustering and our final prediction method of BART (Bayesian Additive Regressive Trees) we can predict students' final mark by week 6 based on mean absolute error to 6.5 percentage points. We provide our R code for implementation of the prediction methods used in a GitHub repository11Abbreviations: Bayesian Additive Regressive Trees (BART); Random Forests (RF); Principal Components Regression (PCR); Multivariate Adaptive Regression Splines (Splines); K-Nearest Neighbours (KNN); Neural Networks (NN) and; Support Vector Machine (SVM). Abbreviations: Bayesian Additive Regressive Trees (BART); Random Forests (RF); Principal Components Regression (PCR); Multivariate Adaptive Regression Splines (Splines); K-Nearest Neighbours (KNN); Neural Networks (NN) and; Support Vector Machine (SVM)}
}
@article{NIYOGISUBIZO2022100066,
title = {Predicting student's dropout in university classes using two-layer ensemble machine learning approach: A novel stacked generalization},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100066},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000212},
author = {Jovial Niyogisubizo and Lyuchao Liao and Eric Nziyumva and Evariste Murwanashyaka and Pierre Claver Nshimyumukiza},
keywords = {Student dropout prediction, Agents of education, Learning analytics, Artificial intelligence, Educational data mining},
abstract = {Student dropout is a serious problem globally. It affects not only the individual who drops out but also the former school, family, and society in general. With the current development of science and technology, big data is emphasized as the most significant technology in data analysis. From the recorded educational data, efficient prediction of students' dropout is currently a hot topic of research. Previous studies have focused only on the students' dropout based on specific levels such as individual, middle school, and university level. However, ensemble learning approaches have not received much research attention so far to predict students' dropout in university classes based on rare datasets. In this paper, we propose a novel stacking ensemble based on a hybrid of Random Forest (RF), Extreme Gradient Boosting (XGBoost), Gradient Boosting (GB), and Feed-forward Neural Networks (FNN) to predict student's dropout in university classes. On the dataset collected from 2016 to 2020 at Constantine the Philosopher University in Nitra, the proposed method has demonstrated greater performance when compared with the base models using testing accuracy and the area under the curve (AUC) evaluation metrics under the same conditions. Based on the findings of this study, students at the risk of dropping out the school can be identified based on influential factors and different agents of education can refer to this information for early intervention in the uncontrolled behavior that can lead to the risk of dropping out and take proactive precautionary measures before the issue arise.}
}
@article{MAAG2022101764,
title = {Learner-facing learning analytic – Feedback and motivation: A critique},
journal = {Learning and Motivation},
volume = {77},
pages = {101764},
year = {2022},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2021.101764},
url = {https://www.sciencedirect.com/science/article/pii/S0023969021000588},
author = {Anelika Maag and Chandana Withana and Srijana Budhathoki and Abeer Alsadoon and Trung Hung VO},
keywords = {Learning analytics, Hybrid, Theory of learning analytics, Learning style, Personality style},
abstract = {Data analysis to guide the design and deployment of learning experiences has been in use in educational institutions for decades. While this has made it possible to predict retention, flags students at risk and more clearly assesses performance across a range of indicators, few benefits visible to students have resulted. Recent attempts to design learner-facing analytics seem to also have met with indifferent results as they appear to have neglected to focus on student personality and motivation or to train students appropriately to decipher LA-based feedback. The aim of this study is to investigate why current Learning Analytics (LA) systems have so little impact on student motivation. A further goal has been to scrutinize the latest research for potential grounding in theoretical concepts generally – but with emphasis on motivation. Results show that, with few exceptions, neither instructor- nor learner-facing LA currently in use at universities take into consideration student personalities as neither are grounded in appropriate theory. This study contributes to the field of LA and Motivation by providing a clear (if bleak) picture of the lack of focus on student personality and motivation in terms of LA feedback. It is, therefore, timely that to remind the research community that an understanding of the learner’s personality, attributes, and sources of motivation is central to the effectiveness of any feedback design. We see this paper as a starting point for a much-needed deeper discussion.}
}
@article{WANG2021104209,
title = {Interpreting log data through the lens of learning design: Second-order predictors and their relations with learning outcomes in flipped classrooms},
journal = {Computers & Education},
volume = {168},
pages = {104209},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104209},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521000865},
author = {Feng Hsu Wang},
keywords = {Flipped classroom, Learning management systems, Online behavioral engagement, Exploratory factor analysis, Multiple linear regression},
abstract = {Flipped classrooms supported by learning management systems (LMS) have been widely adopted by educational institutions. However, earlier studies have found problems with interpreting LMS log data to understand student approaches to learning within the context of a learning design. This study investigates whether it is possible to use LMS log data as a proxy to understand students' learning strategies over different periods of time in the flipped-classroom context. A total of 135 sophomores from two classes of a flipped programming course participated in this study. Exploratory factor analysis is first conducted on the log data to synthesize second-order predictors based on the total-effort model. Then, we investigate the extent to which these second-order predictors relate to students' learning outcomes over time. Four types of learning outcomes are considered, including a quiz, a midterm exam, a final exam and the final grade. For each type of learning outcome, multiple linear regression is used to construct a weekly prediction model from these predictors. Adjusted R-squared and RMSE (Root Mean Square Error) are the metrics used to compare the models. The results show that consistent second-order predictors can be derived from log data, implying that students' clicking events in LMS could manifest students' learning strategies understandable in the design context of a flipped classroom. Furthermore, compared with the first-order models, most of the models constructed using the second-order predictors have higher predictive performance, although with lower data fitness. In addition, the predictive performance of the models with MSLQ (Motivated Strategies for Learning Questionnaire) indicators and past assessment data are also examined. It is found that MSQL variables have a positive but short-termed effect on the models’ predictive ability, while past assessment data greatly improve the models of all types of learning outcomes. Theoretical contributions and implications of the proposed approach for practice, research and future research are discussed.}
}
@article{HU2014469,
title = {Developing early warning systems to predict students’ online learning performance},
journal = {Computers in Human Behavior},
volume = {36},
pages = {469-478},
year = {2014},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2014.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0747563214002118},
author = {Ya-Han Hu and Chia-Lun Lo and Sheng-Pao Shih},
keywords = {Learning management system, e-Learning, Early warning system, Data-mining, Learning performance prediction},
abstract = {An early warning system can help to identify at-risk students, or predict student learning performance by analyzing learning portfolios recorded in a learning management system (LMS). Although previous studies have shown the applicability of determining learner behaviors from an LMS, most investigated datasets are not assembled from online learning courses or from whole learning activities undertaken on courses that can be analyzed to evaluate students’ academic achievement. Previous studies generally focus on the construction of predictors for learner performance evaluation after a course has ended, and neglect the practical value of an “early warning” system to predict at-risk students while a course is in progress. We collected the complete learning activities of an online undergraduate course and applied data-mining techniques to develop an early warning system. Our results showed that, time-dependent variables extracted from LMS are critical factors for online learning. After students have used an LMS for a period of time, our early warning system effectively characterizes their current learning performance. Data-mining techniques are useful in the construction of early warning systems; based on our experimental results, classification and regression tree (CART), supplemented by AdaBoost is the best classifier for the evaluation of learning performance investigated by this study.}
}
@article{BAKER2021100021,
title = {Four paradigms in learning analytics: Why paradigm convergence matters},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100021},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100021},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000151},
author = {Ryan S. Baker and Dragan Gašević and Shamya Karumbaiah},
keywords = {Learning analytics, Artificial intelligence in education, Quantitative ethnography, Learning at scale, Machine learning, Research paradigms},
abstract = {Learning analytics has matured significantly since its early days. The field has rapidly grown in terms of the reputation of its publication venues, established a vibrant community, and has demonstrated an increasing impact on policy and practice. However, the boundaries of the field are still being explored by many researchers in a bid to determine what differentiates a contribution in learning analytics from contributions in related fields, which also center around data in education. In this paper, we propose that instead of emphasizing the examination of differences, a healthy development of the field should focus on collaboration and be informed by the developments in related fields. Specifically, the paper presents a framework for analysis how contemporary fields focused on the study of data in education influence trends in learning analytics. The framework is focused on the methodological paradigms that each of the fields is primarily based on – i.e., essentialist, entatitive/reductionst, ontological/dialectical, and existentialist. The paper uses the proposed framework to analyze how learning analytics (ontological) is being methodologically influenced by recent trends in the fields of educational data mining (entatitive), quantitative ethnography (existentialist), and learning at scale (essentialist). Based on the results of the analysis, this paper identifies gaps in the literature that warrant future research.}
}
@article{HOSSEN2023100191,
title = {Attention monitoring of students during online classes using XGBoost classifier},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100191},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100191},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2300070X},
author = {Muhammad Kamal Hossen and Mohammad Shorif Uddin},
keywords = {Online class, Student engagement, Attention monitoring, Artificial intelligence, Machine learning, XGBoost},
abstract = {With the ever-growing influence of globalization and digitization on education, online learning has gained immense popularity, driven in large part by the global COVID-19 pandemic. In response, educational institutions have rapidly expanded their virtual course offerings and assessment methods. One significant challenge in the realm of online education is the effective assessment of student involvement, engagement, and attentiveness during virtual classes. To address this challenge, we introduce a specialized system tailored to identifying and comprehending the complex range of student behaviors exhibited during online classes. Our system takes into account the diverse contexts and individual considerations that shape students' responses to the online learning environment. It employs user authentication through facial recognition technology and seamlessly integrates vital components, including facial detection, hand tracking, mobile phone detection, and pose estimation modules. Leveraging these components, we extract high-level features to construct a comprehensive dataset for training machine-learning models designed to detect students' attention levels during online classes. After evaluating six prominent machine learning algorithms, we have selected the extreme gradient boosting (XGBoost) algorithm, which demonstrated an impressive 99.75% accuracy on the test data. Finally, the system generates a comprehensive anonymous report on the level of attentiveness of students, accessible through a dedicated webpage that includes a summary of the behavior of students throughout online classes, providing valuable insights for personalized interventions and enhanced online learning experiences.}
}
@article{AZIZAH2024100261,
title = {Predicting at-risk students in the early stage of a blended learning course via machine learning using limited data},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100261},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100261},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400064X},
author = {Zahra Azizah and Tomoya Ohyama and Xiumin Zhao and Yuichi Ohkawa and Takashi Mitsuishi},
keywords = {Academic failure, Academic performance prediction, Motivation, SRL, Learning analytics, Blended learning, Machine learning, SHAP method},
abstract = {Academic failure is a persistent challenge in education. Despite the limited available data, in this study, we focus on identifying at-risk students in a blended learning (BL) course. Several motivational variables are analyzed to determine their effect on student performance. We use a machine-learning classifier to compare two approaches: 1) The benchmark study, which uses data from the same academic year for both training and testing; and 2) a prospective study, which focuses on extrapolating a model trained on the previous fall semester to predict outcomes for the upcoming fall semester. We categorize the motivational variables, including time management and event-occurrence frequency. The window-expansion strategy is adopted to enhance performance through periodic evaluation to facilitate timely intervention. Consequently, the prospective approach is consistent with the benchmark results, thus demonstrating its generalizability across academic years and student populations. This approach is promising for identifying at-risk students in the BL course early. The Shapley additive explanations (SHAP) method emphasizes the importance of time-management variables, particularly study in time, for identifying at-risk students. This study enhances our understanding of early detection methods for at-risk students. By analyzing time-related behaviors, we establish a robust foundation for data-driven decisions to improve future BL implementations as well as support motivation and self-regulated learning practices.}
}
@article{JUNCO201554,
title = {Predicting course outcomes with digital textbook usage data},
journal = {The Internet and Higher Education},
volume = {27},
pages = {54-63},
year = {2015},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2015.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S109675161500041X},
author = {Reynol Junco and Candrianna Clem},
abstract = {Digital textbook analytics are a new method of collecting student-generated data in order to build predictive models of student success. Previous research using self-report or laboratory measures of reading show that engagement with the textbook was related to student learning outcomes. We hypothesized that an engagement index based on digital textbook usage data would predict student course grades. Linear regression analyses were conducted using data from 233 students to determine whether digital textbook usage metrics predicted final course grades. A calculated linear index of textbook usage metrics was significantly predictive of final course grades and was a stronger predictor of course outcomes than previous academic achievement. However, time spent reading, one of the variables that make up the index was more strongly predictive of course outcomes. Additionally, students who were in the top 10th percentile in number of highlights had significantly higher course grades than those in the lower 90th percentile. These findings suggest that digital textbook analytics are an effective early warning system to identify students at risk of academic failure. These data can be collected unobtrusively and automatically and provide stronger prediction of outcomes than prior academic achievement (which to this point has been the single strongest predictor of student success).}
}
@article{LONN201590,
title = {Investigating student motivation in the context of a learning analytics intervention during a summer bridge program},
journal = {Computers in Human Behavior},
volume = {47},
pages = {90-97},
year = {2015},
note = {Learning Analytics, Educational Data Mining and data-driven Educational Decision Making},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2014.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0747563214003793},
author = {Steven Lonn and Stephen J. Aguilar and Stephanie D. Teasley},
keywords = {Learning analytics, Motivation, Early warning systems, At-risk students, Design-based research},
abstract = {Summer bridge programs are designed to improve retention and academic success among at-risk populations in postsecondary education by focusing on successful skills, behaviors, and high impact practices that promote academic performance. Recent research on these programs has focused primarily on how students’ incoming demographics and prior academic performance predict academic performance at the university level. This study investigated changes in students’ academic motivation orientations over the course of one bridge program, and how a learning analytics-based intervention was employed by academic advisors to inform their face-to-face meetings with students. The results of our study show that students’ mastery orientation decreased over the course of the bridge program, and indicate that students’ exposure to displays of their academic performance negatively predicts this change. The findings suggest that student perceptions of their goals and formative performance need to be carefully considered in the design of learning analytics interventions since the resulting tools can affect students’ interpretations of their own data as well as their subsequent academic success.}
}
@article{XUANLAM2024100244,
title = {Enhancing educational evaluation through predictive student assessment modeling},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100244},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100244},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400047X},
author = {Pham {Xuan Lam} and Phan Quoc Hung Mai and Quang Hung Nguyen and Thao Pham and Thi Hong Hanh Nguyen and Thi Huyen Nguyen},
keywords = {Data science applications in education, Educational data mining, Improving classroom teaching, Teaching/learning strategies, Learning analytics},
abstract = {This study evaluates several machine learning models used in predicting student performance. The data utilized in this study was collected from 253 undergraduate students participating in five classes within one of three courses offered by VnCodelab, an interactive learning management system, to provide insights into student performance. Leveraging the data-rich environment of the interactive learning management system proposed earlier, this study focuses on training a predictive model that forecasts student grades based on the comprehensive data collected during the teaching process. The proposed model capitalizes on the data obtained from students' engagement patterns, time spent on exercises, and progress tracking across learning activities. This study compared five different base classifiers— Random Forest (RF), Logistic Regression (LR), Support Vector Machine (SVM), Naïve Bayes (NB), and k-nearest Neighbor (k-NN), and an ensemble learning method Stacking Classifier —utilizing a dataset comprising 13 features. The research assesses the model's accuracy, reliability, and implications, contributing to the evolution of educational evaluation by introducing predictive assessment as a transformative tool. The results indicate that the Stacking Classifier accurately predicts students' grade ranges, surpassing individual base classification models by effectively combining their predictive capabilities. Integrating data-driven forecasting into the educational ecosystem can transform teaching methodologies and foster an informed, engaged, and empowered learning environment. This approach cultivates a proactive learning community by empowering students with real-time academic progress forecasts. Educators benefit from data-informed insights that facilitate more effective and objective performance evaluation.}
}
@article{AKCAPINAR20223818,
title = {Discovering the effects of learning analytics dashboard on students’ behavioral patterns using differential sequence mining},
journal = {Procedia Computer Science},
volume = {207},
pages = {3818-3825},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.443},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922013369},
author = {Gökhan Akçapınar and Mohammad Nehal Hasnine},
keywords = {Learning analytics, intervention, dashboard, temporal learning analytics, differential sequence mining},
abstract = {Interventions based on learning analytics have a very important place in closing the learning analytics loop. However, data-driven studies that test the effects of learning analytics-based interventions on students' online learning behaviors are very limited. In this study, the effect of the student-facing learning analytics dashboard (LAD) on the learning behavior of students in the online learning environment was investigated by using the differential pattern mining method. In a completely remote course, the learning behaviors of the participants before the introduction of the dashboard were compared with the learning behaviors they exhibited after the dashboard was introduced. In this way, it has become possible to analyze the behavior changes after the dashboard intervention. Wilcoxon signed-rank test was used to test whether these behavioral changes were statistically significant or not. According to the Wilcoxon signed-rank test results, while there is no significant difference in terms of students’ assignment and quiz interactions, it is seen that there is a statistically significant increase in terms of students’ forum-related activities such as reading other students’ posts, starting a new discussion, and replying others’ posts. Students’ SCORM interactions (e.g, launch, complete) were also increased after engaging with the LAD. In addition, it was found that the overall interaction of students in the online learning environment increased by 57% when the LAD was used.}
}
@article{VIBERG201898,
title = {The current landscape of learning analytics in higher education},
journal = {Computers in Human Behavior},
volume = {89},
pages = {98-110},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218303492},
author = {Olga Viberg and Mathias Hatakka and Olof Bälter and Anna Mavroudi},
keywords = {Learning analytics, Literature review, Higher education, Research methods, Evidence},
abstract = {Learning analytics can improve learning practice by transforming the ways we support learning processes. This study is based on the analysis of 252 papers on learning analytics in higher education published between 2012 and 2018. The main research question is: What is the current scientific knowledge about the application of learning analytics in higher education? The focus is on research approaches, methods and the evidence for learning analytics. The evidence was examined in relation to four earlier validated propositions: whether learning analytics i) improve learning outcomes, ii) support learning and teaching, iii) are deployed widely, and iv) are used ethically. The results demonstrate that overall there is little evidence that shows improvements in students' learning outcomes (9%) as well as learning support and teaching (35%). Similarly, little evidence was found for the third (6%) and the forth (18%) proposition. Despite the fact that the identified potential for improving learner practice is high, we cannot currently see much transfer of the suggested potential into higher educational practice over the years. However, the analysis of the existing evidence for learning analytics indicates that there is a shift towards a deeper understanding of students’ learning experiences for the last years.}
}
@article{DENG2019166,
title = {PerformanceVis: Visual analytics of student performance data from an introductory chemistry course},
journal = {Visual Informatics},
volume = {3},
number = {4},
pages = {166-176},
year = {2019},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2019.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X1930049X},
author = {Haozhang Deng and Xuemeng Wang and Zhiyi Guo and Ashley Decker and Xiaojing Duan and Chaoli Wang and G. {Alex Ambrose} and Kevin Abbott},
keywords = {Student performance, Item analysis, Grade prediction, Learning analytics, Knowledge discovery},
abstract = {We present PerformanceVis, a visual analytics tool for analyzing student admission and course performance data and investigating homework and exam question design. Targeting a university-wide introductory chemistry course with nearly 1000 student enrollment, we consider the requirements and needs of students, instructors, and administrators in the design of PerformanceVis. We study the correlation between question items from assignments and exams, employ machine learning techniques for student grade prediction, and develop an interface for interactive exploration of student course performance data. PerformanceVis includes four main views (overall exam grade pathway, detailed exam grade pathway, detailed exam item analysis, and overall exam & homework analysis) which are dynamically linked together for user interaction and exploration. We demonstrate the effectiveness of PerformanceVis through case studies along with an ad-hoc expert evaluation. Finally, we conclude this work by pointing out future work in this direction of learning analytics research.}
}
@article{SANTOS2023100175,
title = {Accurate, timely, and portable: Course-agnostic early prediction of student performance from LMS logs},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100175},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100175},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000541},
author = {Ricardo Miguel Santos and Roberto Henriques},
keywords = {Learning management systems, Higher education, Machine learning, Early prediction, Student performance},
abstract = {In higher education, providing personalized feedback and support to students is a significant challenge. Early warning systems can help by identifying both at-risk and high-performing students, allowing for timely interventions and enhanced learning opportunities. In our study, we used a year's worth of data from an information management school to build predictive models for two binary classification problems: identifying at-risk students and high-performing students. We employed traditional machine learning classifiers and long-short term memory units (LSTM), testing them at various stages of course completion. The best performance was achieved using all course data, with an AUC of 0.756 for at-risk students and 78.2% accuracy for high-performing students using Random Forest and Extremely Randomized Trees, respectively. We found that early prediction was possible as early as 25% course completion. Although LSTM showed inferior performance, it offered practical advantages for early prediction. Our findings suggest that static LMS logs can be reliable indicators of student success early in a course, and a course-agnostic time-dependent representation of the number of clicks can offer a worthwhile tradeoff between predictive performance and simplicity in implementation in some instances. These findings have important implications as they suggest the potential for automated early warning systems that can help educators identify students of interest and allocate resources where they are most needed. However, implementing these systems in real-time requires clear protocols and responsible policies. Further research should explore the generalizability of findings across different contexts and continuously evaluate their real-world effectiveness.}
}
@article{WAHEED2023118868,
title = {Early prediction of learners at risk in self-paced education: A neural network approach},
journal = {Expert Systems with Applications},
volume = {213},
pages = {118868},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118868},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422018863},
author = {Hajra Waheed and Saeed-Ul Hassan and Raheel Nawaz and Naif R. Aljohani and Guanliang Chen and Dragan Gasevic},
keywords = {Early prediction, Machine learning, Deep learning, Long short-term memory (LSTM), Students at risk, Virtual learning environment (VLE)},
abstract = {To address the demands of modern education and increase flexibility, many higher education institutions are considering self-paced education programs. However, student retention is yet a widely recognized challenge faced in self-paced education. While many studies have examined the potential of the use of data about student interaction with learning technologies to predict student success, studies that focus on self-paced education are scarce. To address this gap in the literature, this paper reports on the findings of a study that has investigated the performance of a well-known deep learning technique i.e., Long Short-term Memory (LSTM), in the prediction of students at risk of failing a course offered in a self-paced mode of online education. The study has utilized a freely accessible Open University Learning Analytics Dataset comprising 22,437 students with 69 % pass, and 31 % failed instances. The deep LSTM shows the highest predictive power to classify between pass and fail students, compared to all other alternatives by achieving an accuracy of 84.57 %, precision of 82.24 % and recall of 79.43 %. Interestingly, with only first five weeks of course activity log data used for training, the receiver operating characteristic based diagnostic accuracy of the LSTM algorithm is achieved up to 71 %, that outperforms almost all other conventional algorithms - despite trained on the complete dataset collected for the entire duration of the course i.e. up to 38 weeks. Furthermore, this study has also employed a shapely additive explanation model to identify the most important predictors of student retention, e.g., assessment submission and attempted quizzes. This approach is essential in order to increase the interpretability of deep learning techniques and, thus, increase their potential to generate actionable insights.}
}
@article{K20242716,
title = {Optimizing Academic Journey for High Schoolers in Oman: A Machine Learning-Enabled AI Model},
journal = {Procedia Computer Science},
volume = {235},
pages = {2716-2729},
year = {2024},
note = {International Conference on Machine Learning and Data Engineering (ICMLDE 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.04.256},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924009323},
author = {Suresh Manic K and Al-Bemani A.S. and Nizamudin A.A. and Balaji G and Amal A.A.},
keywords = {Artificial Intelligence, Machine learning, Data Mining, Predictive model, Educational Guidance},
abstract = {This article presents a comprehensive exploration of the development of an AI-driven Gen-Alpha education guidance indicator for Oman, employing cutting-edge machine learning techniques. The primary objective is to deliver a highly personalized support system and guidance mechanism that accompanies students throughout their academic journey. The research places a spotlight on the pivotal role of Artificial Intelligence (AI) within the realm of education. It skillfully demonstrates AI’s robust capabilities in accurately forecasting student performance through the effective use of data mining and advanced machine learning techniques. An integral aspect of this research is the application of AI in aiding students to navigate the involved process of subject selection for their higher education pursuits. This multidimensional process encompasses exhaustive data collection, the detailed creation of a sophisticated machine learning model, and the application of a diverse array of state-of-the-art algorithms. Among these algorithms, K-Nearest Neighbors (KNN), Decision Trees, Random Forest, and Support Vector Machines (SVM) stand out prominently. Notably, the SVM algorithm emerges as the outright winner, delivering an extraordinary accuracy rate of 77%. This remarkable achievement underscores the model’s unwavering robustness and its potential to redefine the educational landscape in Oman. In essence, this paper transcends the boundaries of conventional research and offers conclusive validation of AI’s revolutionary potential in reshaping educational paradigms. By facilitating data-driven decision-making, the AI-driven Gen-Alpha education guidance indicator empowers students to embark on their educational journeys well-informed and confident, thereby playing a pivotal role in advancing Oman’s education system.}
}