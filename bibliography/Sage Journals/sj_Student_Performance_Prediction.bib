@article{doi:10.1177/02666669231213023,
author = {Yavuz Selim Balcioğlu and Melike Artar},
title = {Predicting academic performance of students with machine learning},
journal = {Information Development},
volume = {0},
number = {0},
pages = {02666669231213023},
year = {2023},
doi = {10.1177/02666669231213023},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/02666669231213023},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/02666669231213023},
abstract = {This study investigates the effectiveness of machine learning and deep learning models for early prediction of student performance in higher education institutions. Using the Open University Learning Analytics (OULA) dataset, various models, including Decision Tree, Support Vector Machine, Neural Network, and Ensemble Model, were employed to predict student performance in three categories: Pass/Fail, Close to Fail, and Close to Pass. The Ensemble Model (EM) consistently outperformed other models, achieving the highest overall F1 measure, precision, recall, and accuracy. These results highlight the potential of data-driven techniques in informing educational stakeholders’ decision-making processes, enabling targeted interventions, and facilitating personalized learning strategies tailored to students’ needs. By identifying at-risk students early in the academic year, institutions can provide additional support to improve academic outcomes and retention rates. The study also discusses practical implications, including the development of pedagogical policies and guidelines based on early predictions, which can help educational institutions maintain strong academic outcomes and enhance their reputation for academic excellence. Future research aims to investigate the impact of individual activities on student performance and explore day-to-day student behaviors, enabling the creation of tailored pedagogical policies and guideline.}
}
@article{doi:10.1177/0002716219846850,
author = {John T. Behrens and Kristen E. DiCerbo and Peter W. Foltz},
title = {Assessment of Complex Performances in Digital Environments},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {683},
number = {1},
pages = {217–232},
year = {2019},
doi = {10.1177/0002716219846850},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/0002716219846850},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/0002716219846850},
abstract = {Digital technologies hold the potential to transform educational assessment. Recent advances reveal that digital environments will support the development of learning and assessment activities in ways that will both increase the inferential fidelity of assessments and change the form of assessments altogether. Digital technologies can also automate data collection and the production of assessment inferences on a massive scale. Here, we discuss the wide variation in digital learning experiences and explain how they are transforming traditional language for discussing assessment. We argue that the predigital constraints on assessment have skewed our thinking about assessment and give examples of new and novel approaches. Second, we discuss how digital environments can allow us to capture and make inferences from simple or complex learning activities in new ways. Third, we point to advances in machine learning and AI that have the potential to change current and future assessment practices. Finally, we argue for balancing enthusiasm for digital environments against the challenges of making appropriate assessment inferences.}
}
@article{doi:10.1177/00472395221138791,
author = {Sima Caspari-Sadeghi},
title = {Artificial Intelligence in Technology-Enhanced Assessment: A Survey of Machine Learning},
journal = {Journal of Educational Technology Systems},
volume = {51},
number = {3},
pages = {372–386},
year = {2023},
doi = {10.1177/00472395221138791},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395221138791},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395221138791},
abstract = {Intelligent assessment, the core of any AI-based educational technology, is defined as embedded, stealth and ubiquitous assessment which uses intelligent techniques to diagnose the current cognitive level, monitor dynamic progress, predict success and update students’ profiling continuously. It also uses various technologies, such as learning analytics, educational data mining, intelligent sensors, wearables and machine learning. This can be the key to Precision Education (PE): adaptive, tailored, individualized instruction and learning. This paper explores (a) the applications of Machine Learning (ML) in intelligent assessment, and (b) the use of deep learning models in ‘knowledge tracing and student modeling’. The paper concludes by discussing barriers involved in using state-of-the-art ML methods and some suggestions to unleash the power of data and ML to improve educational decision-making.}
}
@article{doi:10.1177/0958305X231160590,
author = {Mariana Haddadin and Omar Mohamed and Wejdan Abu Elhaija and Mustafa Matar},
title = {Performance prediction  of a clean coal power plant via machine learning and deep learning techniques},
journal = {Energy & Environment},
volume = {0},
number = {0},
pages = {0958305X231160590},
year = {2023},
doi = {10.1177/0958305X231160590},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/0958305X231160590},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/0958305X231160590},
abstract = {Computer simulation of energy resources has led to significant achievements in the interdisciplinary fields of energy and environment. Apart from renewable resources, fossil-fuel power generation plants can be made cleaner to satisfy the future climate targets while keeping secure and stable grid. Clean coal power plants are still among the dominant options for power generation, which are committed through energy-efficient operation, carbon capture and storage, or combination of both strategies. On the other hand, machine learning and deep learning techniques have a leading integrity in the field of simulation. This paper presents accurate models of a cleaner coal-fired supercritical (SC) unit using two types of artificial neural network, which are Elman neural network (ENN) and generalized regression neural network (GRNN). The models newly embed higher coverage range and more accurate results than previously published models. Each subsystem of the models has been structured as a multi-input single-output (MISO) component to predict the behavior of significant variables in the plant, mainly the supercritical pressure in MPa, the steam temperature in °C and the production in MW. Those variables have been intentionally selected as they are clear indicators for the energy-efficient and cleaner production. Simulation results of four sets of data have indicated satisfactory performance of both models with a bit higher superiority of the GRNN that has given negligible or zero Mean Squared Error (MSE) for all outputs, whereas the minimum MSE of the deep ENN is 3.131  ×  10−3.}
}
@article{doi:10.1177/01430343221122453,
author = {Hao Lei and Xijing Wang and Ming Ming Chiu and Mingfeng Du and Tongwei Xie},
title = {Teacher-student relationship and academic achievement in China: Evidence from a three-level meta-analysis},
journal = {School Psychology International},
volume = {44},
number = {1},
pages = {68–101},
year = {2023},
doi = {10.1177/01430343221122453},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/01430343221122453},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/01430343221122453},
abstract = {Past studies of the relation between teacher-student relationship (TSR) and students’ academic achievement (SAA) yielded mixed results, so this study determined the overall link between TSR and SAA, along with their moderators. This three-level meta-analysis of 90 independent effect sizes in 74 empirical studies of 233,961 students showed an overall positive link between TSR and SAA in China (r  =  .259, 95% CI  =  [.227; .290]). This relationship was higher in: (a) China’s central region (.305) than its eastern (.238) or western regions (.166); (b) senior high school (.345), followed by junior high school (.251), then primary school (.221); (c) English (.302), followed by math (.272), Chinese (.269), and science (.202); and (d) females (B  =  .507) than males. These results suggest the value of improving teacher-student relationships in policies and practices.}
}
@article{doi:10.1177/00472395231191139,
author = {Fidelia A. Orji and Julita Vassileva},
title = {Modeling the Impact of Motivation Factors on Students’ Study Strategies and Performance Using Machine Learning},
journal = {Journal of Educational Technology Systems},
volume = {52},
number = {2},
pages = {274–296},
year = {2023},
doi = {10.1177/00472395231191139},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395231191139},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395231191139},
abstract = {This research presents a proposed approach that could be applied in modeling students’ study strategies and performance in higher education. The research used key learning attributes, including intrinsic motivation, extrinsic motivation, autonomy, relatedness, competence, and self-esteem in the modeling. Five machine learning models were implemented, trained, evaluated, and tested with data from 924 university students. The comparative analysis reveals that tree-based models, particularly random forest and decision trees, outperform other models, achieving a prediction accuracy of 94.9%. The models built in this research can be used in predicting student study strategies and performance and this can be applied in implementing targeted interventions for improving learning progress. The research findings emphasize the importance of incorporating strategies that address diverse motivation dimensions in online educational systems, as it increases student engagement and promotes continuous learning. The findings also highlight the potential for modeling these attributes collectively to personalize and adapt learning process.}
}
@article{doi:10.1177/00472395231185843,
author = {S.J. Shabnam Ara and R. Tanuja and S.H. Manjula and K.R. Venugopal},
title = {A Comprehensive Survey on Usage of Learning Analytics for Enhancing Learner’s Performance in Learning Portals},
journal = {Journal of Educational Technology Systems},
volume = {52},
number = {2},
pages = {245–273},
year = {2023},
doi = {10.1177/00472395231185843},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395231185843},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395231185843},
abstract = {Learning analytics (LA) is considered a promising field of study as it’s helping to improve learning and the context in which it occurs. A learner’s performance can be defined as how well students are learning in terms of knowledge and skills development and can be analyzed based on students’ outcomes and engagement in the course. We have consolidated the work carried out from 2011 to 2022 to improve learners’ performance using LA, describe criteria that define learners’ performance, discuss parameters that impact learners’ performance, and how predictive models can be created to forecast learners’ performance using these parameters. Results showed that the data collected from log files of the Learning Management System (LMS) had been used to get insights into the learner’s performance in online platforms and LA could bring incredible benefits in the field of the education sector, such as improvement of learners’ involvement with learning activities as well as learning outcomes, identification of students at risk, providing real-time feedback, and personalization of learning. Hence, we can say usage of LA significantly helps learners’ performance improvement in learning portals. But we can get better results if we augment data from log files of LMS with the learner’s personal data from his birth to the current moment, which is a bit challenging with respect to data collection i.e., huge and from multiple sources.}
}
@article{doi:10.3102/1076998620951983,
author = {Youmi Suk and Jee-Seon Kim and Hyunseung Kang},
title = {Hybridizing Machine Learning Methods and Finite Mixture Models for Estimating Heterogeneous Treatment Effects in Latent Classes},
journal = {Journal of Educational and Behavioral Statistics},
volume = {46},
number = {3},
pages = {323–347},
year = {2021},
doi = {10.3102/1076998620951983},
URL = {https://doi-org.ez.unisabana.edu.co/10.3102/1076998620951983},
eprint = {https://doi-org.ez.unisabana.edu.co/10.3102/1076998620951983},
abstract = {There has been increasing interest in exploring heterogeneous treatment effects using machine learning (ML) methods such as causal forests, Bayesian additive regression trees, and targeted maximum likelihood estimation. However, there is little work on applying these methods to estimate treatment effects in latent classes defined by well-established finite mixture/latent class models. This article proposes a hybrid method, a combination of finite mixture modeling and ML methods from causal inference to discover effect heterogeneity in latent classes. Our simulation study reveals that hybrid ML methods produced more precise and accurate estimates of treatment effects in latent classes. We also use hybrid ML methods to estimate the differential effects of private lessons across latent classes from Trends in International Mathematics and Science Study data.}
}
@article{doi:10.1177/07356331211048777,
author = {Ruangsak Trakunphutthirak and Vincent C. S. Lee},
title = {Application of Educational Data Mining Approach for Student Academic Performance Prediction Using Progressive Temporal Data},
journal = {Journal of Educational Computing Research},
volume = {60},
number = {3},
pages = {742–776},
year = {2022},
doi = {10.1177/07356331211048777},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331211048777},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331211048777},
abstract = {Educators in higher education institutes often use statistical results obtained from their online Learning Management System (LMS) dataset, which has limitations, to evaluate student academic performance. This study differs from the current body of literature by including an additional dataset that advances the knowledge about factors affecting student academic performance. The key aims of this study are fourfold. First, is to fill the educational literature gap by applying machine learning techniques in educational data mining, making use of the Internet usage behaviour log files and LMS data. Second, LMS data and Internet usage log files were analysed with machine learning techniques for predicting at-risk-of-failure students, with greater explanation added by combining student demographic data. Third, the demographic features help to explain the prediction in understandable terms for educators. Fourth, the study used a range of Internet usage data, which were categorized according to type of usage data and type of web browsing data to increase prediction accuracy.}
}
@article{doi:10.1177/0735633120960422,
author = {Wanli Xing and Chenglu Li and Guanhua Chen and Xudong Huang and Jie Chao and Joyce Massicotte and Charles Xie},
title = {Automatic Assessment of Students’ Engineering Design Performance Using a Bayesian Network Model},
journal = {Journal of Educational Computing Research},
volume = {59},
number = {2},
pages = {230–256},
year = {2021},
doi = {10.1177/0735633120960422},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/0735633120960422},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/0735633120960422},
abstract = {Integrating engineering design into K-12 curricula is increasingly important as engineering has been incorporated into many STEM education standards. However, the ill-structured and open-ended nature of engineering design makes it difficult for an instructor to keep track of the design processes of all students simultaneously and provide personalized feedback on a timely basis. This study proposes a Bayesian network model to dynamically and automatically assess students’ engagement with engineering design tasks and to support formative feedback. Specifically, we applied a Bayesian network to 111 ninth-grade students’ process data logged by a computer-aided design software program that students used to solve an engineering design challenge. Evidence was extracted from the log files and fed into the Bayesian network to perform inferential reasoning and provide a barometer of their performance in the form of posterior probabilities. Results showed that the Bayesian network model was competent at predicting a student’s task performance. It performed well in both identifying students of a particular group (recall) and ensuring identified students were correctly labeled (precision). This study also suggests that Bayesian networks can be used to pinpoint a student’s strengths and weaknesses for applying relevant science knowledge to engineering design tasks. Future work of implementing this tool within the computer-aided design software will provide instructors a powerful tool to facilitate engineering design through automatically generating personalized feedback to students in real time.}
}
@article{doi:10.1177/00219347241240788,
author = {Paris B. Adkins-Jackson and Janine A. Jackson and Tonya Ross Taylor and Elana R. Levine and Anisha Makhija and Alyasah Ali Sewell},
title = {Black Measurement: The Contributions of People Racialized as Black to the Field of Psychometrics},
journal = {Journal of Black Studies},
volume = {55},
number = {6},
pages = {471–492},
year = {2024},
doi = {10.1177/00219347241240788},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00219347241240788},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00219347241240788},
abstract = {Psychometrics is a branch of psychology concerned with the measurement of mental attributes, behavior, and performance, in addition to the design and analysis of tests and other instruments. The origins of this field are rooted in the explorations of 18th century scientists concerned with capturing phenomena in empirical ways. Less discussed is the use of tests and assessments to validate racialization, which thrusts persons racialized as Black into the early discourse on psychometrics. Scholars, scientists, and psychometricians racialized as Black have long engaged psychometrics providing two major contributions: infrastructure via personnel and training programs built by persons racialized as Black; and interdisciplinarity, which include disciplinary standards and knowledge production. This commentary names these important figures and describes their contributions to the field of psychometrics.}
}
@article{doi:10.1177/01626434241232117,
author = {Nikola Ebenbeck and Markus Gebhardt},
title = {Differential Performance of Computerized Adaptive Testing in Students With and Without Disabilities – A Simulation Study},
journal = {Journal of Special Education Technology},
volume = {0},
number = {0},
pages = {01626434241232117},
year = {2024},
doi = {10.1177/01626434241232117},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/01626434241232117},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/01626434241232117},
abstract = {Technologies that enable individualization for students have significant potential in special education. Computerized Adaptive Testing (CAT) refers to digital assessments that automatically adjust their difficulty level based on students’ abilities, allowing for personalized, efficient, and accurate measurement. This article examines whether CAT performs differently for students with and without special educational needs (SEN). Two simulation studies were conducted using a sample of 709 third-grade students from general and special schools in Germany, who took a reading test. The results indicate that students with SEN were assessed with fewer items, reduced bias, and higher accuracy compared to students without SEN. However, measurement accuracy decreased, and test length increased for students whose abilities deviated more than two SD from the norm. We discuss potential adaptations of CAT for students with SEN in the classroom, as well as the integration of CAT with AI-supported feedback and tailored exercises within a digital learning environment.}
}
@article{doi:10.1080/11356405.2018.1551653,
author = {Paula Elosua},
title = {Performance factors and immigration. Impact of individual and school variables / Factores de rendimiento e inmigración. Impacto de variables individuales y escolares},
journal = {Culture and Education},
volume = {31},
number = {1},
pages = {1–30},
year = {2019},
doi = {10.1080/11356405.2018.1551653},
URL = {https://doi-org.ez.unisabana.edu.co/10.1080/11356405.2018.1551653},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1080/11356405.2018.1551653},
abstract = {The way schools address migratory movements has a direct impact on integration and social cohesion, making the in-depth study of factors that affect the lower performance of immigrant students in comparison with non-immigrants essential. Using a methodology based on random coefficient models, this paper analyses the differential effect of individual level and school level variables on the estimation of mathematical competence in non-immigrant and immigrant populations. Data are extracted from an educational assessment programme carried out in the Basque Autonomous Community. The sample consists of 16,981 students with an average age of 13.7 years, of which 1,369 are immigrant students. The results reveal that individual and family-level variables show significantly higher impact on student performance than school-level variables. The article concludes by emphasizing the importance of investing in policies to support diversity that work at family level, as a means to achieve fuller equit.}
}
@article{doi:10.1177/00472395241231815,
author = {K. Kavitha and V. P. Joshith},
title = {The Transformative Trajectory of Artificial Intelligence in Education: The Two Decades of Bibliometric Retrospect},
journal = {Journal of Educational Technology Systems},
volume = {52},
number = {3},
pages = {376–405},
year = {2024},
doi = {10.1177/00472395241231815},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395241231815},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00472395241231815},
abstract = {Integrating artificial intelligence (AI) stands out as the most dynamic and innovative breakthrough in introducing disruptive paths in the varied domains of education. This bibliometric analysis delved into the trajectory of AI’s evolving landscape within educational settings over two decades, encompassing 324 articles published from 2003 to 2023, sourced from the Scopus database. The study uncovers a substantial surge in publications with a steep increase from 2020, peaking in 2023. Notably, while established nations like China and the US lead in publications, notable contributions from other developing countries, including Saudi Arabia, India, and Malaysia, underscored a global shift. Key terms, including students, machine learning, AI and higher education, underpin the central focus research areas while emerging themes like “generative AI” and chatbots like “chatgpt” mark the evolving trends. Further, the study prompts sustained global partnerships, interdisciplinary collaborations, and continued exploration of emerging AI technologies to catalyze educational advancements.}
}
@article{doi:10.1177/20539517231176230,
author = {Matthew Kopec and Meica Magnani and Vance Ricks and Roben Torosyan and John Basl and Nicholas Miklaucic and Felix Muzny and Ronald Sandler and Christo Wilson and Adam Wisniewski-Jensen et al.},
title = {The effectiveness of embedded values analysis modules in Computer Science education: An empirical study},
journal = {Big Data & Society},
volume = {10},
number = {1},
pages = {20539517231176230},
year = {2023},
doi = {10.1177/20539517231176230},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/20539517231176230},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/20539517231176230},
abstract = {Embedding ethics modules within computer science courses has become a popular response to the growing recognition that computer science programs need to better equip their students to navigate the ethical dimensions of computing technologies such as artificial intelligence, machine learning, and big data analytics. However, the popularity of this approach has outpaced the evidence of its positive outcomes. To help close that gap, this empirical study reports positive results from Northeastern University’s program that embeds values analysis modules into computer science courses. The resulting data suggest that such modules have a positive effect on students’ moral attitudes and that students leave the modules believing they are more prepared to navigate the ethical dimensions they will likely face in their eventual careers. Importantly, these gains were accomplished at an institution without a philosophy doctoral program, suggesting this strategy can be effectively employed by a wider range of institutions than many have thought.}
}
@article{doi:10.1177/07356331221136888,
author = {Hsin-Yu Lee and Yu-Ping Cheng and Wei-Sheng Wang and Chia-Ju Lin and Yueh-Min Huang},
title = {Exploring the Learning Process and Effectiveness of STEM Education via Learning Behavior Analysis and the Interactive-Constructive- Active-Passive Framework},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {5},
pages = {951–976},
year = {2023},
doi = {10.1177/07356331221136888},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221136888},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221136888},
abstract = {Given the inadequacy of assessed outcomes (e.g., final exam) and the importance of evaluating the learning process in STEM education, we use deep learning to develop the STEM learning behavior analysis system (SLBAS) to assess the behavior of learners in STEM education. We map learner behavior to the ICAP (interactive, constructive, active, passive) framework, helping instructors to better understand the learning process of learners. The results show that SLBAS exhibits high accuracy. Moreover, Cohen’s kappa coefficient between expert coding and SLBAS is high enough to support replacing expert coding in the observation method with SLBAS to recognize the learning process of learners during STEM activities. Finally, statistical analysis establishes a correlation between the learning process and learning effectiveness. The results of this study are in line with most previous studies, demonstrating that STEM education differs from traditional teacher-centered courses in that it helps learners to improve the process of knowledge construction with practice and hands-on opportunities rather than simply receiving knowledge passively.}
}
@article{doi:10.1177/21582440241242180,
author = {Lin Lin and Danhua Zhou and Jingying Wang and Yu Wang},
title = {A Systematic Review of Big Data Driven Education Evaluation},
journal = {Sage Open},
volume = {14},
number = {2},
pages = {21582440241242180},
year = {2024},
doi = {10.1177/21582440241242180},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/21582440241242180},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/21582440241242180},
abstract = {The rapid development of artificial intelligence has driven the transformation of educational evaluation into big data-driven. This study used a systematic literature review method to analyzed 44 empirical research articles on the evaluation of big data education. Firstly, it has shown an increasing trend year by year, and is mainly published in thematic journals such as educational technology, science education, and language teaching. Chinese and American researchers have made the greatest contributions in this field. Secondly, the algorithmic models for big data education evaluation research are diverse, the text modality is the most popular, the evaluation subjects are mainly college students, with fewer primary and secondary school students, and science is the discipline that most commonly applies big data education evaluation. The evaluation objectives of big data education evaluation mainly focus on five aspects: high-order thinking analysis, learning performance prediction, learning emotion recognition, teaching management decision-making, and evaluation mode optimization, and the text modality is widely used for data collection in high-order thinking analysis; regardless of the evaluation objectives, higher education students are the most widely evaluated objects; the science discipline is the main field of using big data technology to empower teaching evaluation. Thirdly, the current research topics of big data education evaluation mainly focus on online learning behavior and environmental participation evaluation, process assessment of learning motivation and emotional analysis, development and optimization of subject domain big data models, cognitive diagnosis and high-order thinking skills evaluation, and design of learning analysis frameworks based on data minin.}
}
@article{doi:10.1177/07356331221129765,
author = {Ryusuke Murata and Fumiya Okubo and Tsubasa Minematsu and Yuta Taniguchi and Atsushi Shimada},
title = {Recurrent Neural Network-FitNets: Improving Early Prediction of Student Performanceby Time-Series Knowledge Distillation},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {3},
pages = {639–670},
year = {2023},
doi = {10.1177/07356331221129765},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221129765},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221129765},
abstract = {This study helps improve the early prediction of student performance by RNN-FitNets, which applies knowledge distillation (KD) to the time series direction of the recurrent neural network (RNN) model. The RNN-FitNets replaces the teacher model in KD with “an RNN model with a long-term time-series in which the features during the entire course are inputted” and the student model in KD with “an RNN model with a short-term time-series in which only the features during the early stages are inputted.” As a result, the RNN model in the early stage was trained to output the same results as the more accurate RNN model in the later stages. The experiment compared RNN-FitNets with a normal RNN model on a dataset of 296 university students in total. The results showed that RNN-FitNets can improve early prediction. Moreover, the SHAP value was employed to explain the contribution of the input features to the prediction results by RNN-FitNets. It was shown that RNN-FitNets can consider the future effects of the input features from the early stages of the course.}
}
@article{doi:10.3102/0091732X18821116,
author = {Philip J. Piety},
title = {Components, Infrastructures, and Capacity: The Quest for the Impact of Actionable Data Use on P–20 Educator Practice},
journal = {Review of Research in Education},
volume = {43},
number = {1},
pages = {394–421},
year = {2019},
doi = {10.3102/0091732X18821116},
URL = {https://doi-org.ez.unisabana.edu.co/10.3102/0091732X18821116},
eprint = {https://doi-org.ez.unisabana.edu.co/10.3102/0091732X18821116},
abstract = {This chapter reviews actionable data use—both as an umbrella term and as a specific concept—developed in three different traditions that data/information can inform and guide P–20 educational practice toward better outcomes. The literatures reviewed are known as data-driven decision making (DDDM), education data mining (EDM), and learning analytics (LA). DDDM is grounded in K–12 settings, has a social orientation, and is shaped by policy. EDM and LA began in higher education using data provided by instructional tools. This review of more than 1,500 publications traced patterns in these communities revealing disciplinary disconnects between DDDM and EDM/LA. Recognizing information’s systemic nature, this review expanded the analysis from teacher practice to educator practice. While methodological progress has been made in all areas, studies of impact were concentrated in DDDM. EDM and LA focus on tools for current/future educational settings and leveraging data harvested for basic research while reconceiving learning practices. The DDDM impact studies did not support a directly beneficial model for data use. Rather, long timescale capacity factors, including cultural and organizational processes that impact data use were revealed. A complementary model of components, infrastructure, and capacity is advanced with recommendations for scholarship in education’s sociotechnical future.}
}
@article{doi:10.1177/07356331221113613,
author = {Wanli Xing and Hanxiang Du},
title = {Mining Large Open Online Learning Networks: Exploring Community Dynamics and Communities of Performance},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {2},
pages = {390–415},
year = {2023},
doi = {10.1177/07356331221113613},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221113613},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221113613},
abstract = {Online learning communities are becoming increasingly popular as they are known to support collaborative dialogue and knowledge building. Previous studies have typically focused on small, closed learning communities from an individual, static, and aggregated perspective. This research aims to advance our understanding of open and large online learning networks by exploring and characterizing community level dynamics and communities of performance. To achieve this goal, we mined a large open online learning network of over 30,000 students and approximately one million posts. First, we analyzed overall community network development by building temporal social networks. Subsequently, we studied sub-community dynamics using community detection algorithms, and, following that, investigated the interaction between community dynamics and communities of performance using best colleague correlation and Kruskal-Wallis test. Results found that large open online learning communities begin with a very large network having numerous small sub-communities. These communities consist of students who are similar in performance with strong links. The overall network size gradually shrinks, as does the number of sub-communities, and these communities evolve over time for their membership formulation with students who are more different in performance with weaker ties. Theoretical, practical, and methodological implications are then discussed. This study pushed the online learning community research to examine large and open networks by taking a more community-based and dynamic view of investigation.}
}
@article{doi:10.3102/00028312221106773,
author = {Dandan Chen and Michael Hebert and Joshua Wilson},
title = {Examining Human and Automated Ratings of Elementary Students’ Writing Quality: A Multivariate Generalizability Theory Application},
journal = {American Educational Research Journal},
volume = {59},
number = {6},
pages = {1122–1156},
year = {2022},
doi = {10.3102/00028312221106773},
URL = {https://doi-org.ez.unisabana.edu.co/10.3102/00028312221106773},
eprint = {https://doi-org.ez.unisabana.edu.co/10.3102/00028312221106773},
abstract = {We used multivariate generalizability theory to examine the reliability of hand-scoring and automated essay scoring (AES) and to identify how these scoring methods could be used in conjunction to optimize writing assessment. Students (n = 113) included subsamples of struggling writers and non-struggling writers in Grades 3–5 drawn from a larger study. Students wrote six essays across three genres. All essays were hand-scored by four raters and an AES system called Project Essay Grade (PEG). Both scoring methods were highly reliable, but PEG was more reliable for non-struggling students, while hand-scoring was more reliable for struggling students. We provide recommendations regarding ways of optimizing writing assessment and blending hand-scoring with AES.}
}
@article{doi:10.3102/00346543221081552,
author = {Lois Ruth Harris and Lenore Adie and Claire Wyatt-Smith},
title = {Learning Progression–Based Assessments: A Systematic Review of Student and Teacher Uses},
journal = {Review of Educational Research},
volume = {92},
number = {6},
pages = {996–1040},
year = {2022},
doi = {10.3102/00346543221081552},
URL = {https://doi-org.ez.unisabana.edu.co/10.3102/00346543221081552},
eprint = {https://doi-org.ez.unisabana.edu.co/10.3102/00346543221081552},
abstract = {This systematic review examined evidence of the utility of learning progression (LP)–based assessments to inform teaching and student learning in classroom contexts. Fifty-nine studies met inclusion criteria and were analyzed against four research questions. Evidence highlighted their potential for supporting judgments about learning, informing instructional and learning decisions, and improving teacher learning and development. Although 23 studies measured student achievement, reporting positive overall effects, only 6 adopted the experimental designs necessary for causal claims. Using LP-based assessment for formative purposes was well supported. Limited evidence was found regarding summative and accountability uses. Findings show that LP-based assessment design and use requires trade-offs relating to standardization and scale. Teachers need opportunities for negotiation when making judgments and integrating LP-based assessments into existing curriculum and policy contexts. Future research should examine student use of LP assessments and find a balance between standardization and customization to meet the needs of diverse learners and local contexts.}
}
@article{doi:10.3102/10769986241257963,
author = {Matthew S. Johnson},
title = {How Do We Demonstrate AI Responsibility: The Devil Is in the Details},
journal = {Journal of Educational and Behavioral Statistics},
volume = {0},
number = {0},
pages = {10769986241257964},
year = {2024},
doi = {10.3102/10769986241257963},
URL = {https://doi-org.ez.unisabana.edu.co/10.3102/10769986241257963},
eprint = {https://doi-org.ez.unisabana.edu.co/10.3102/10769986241257963},
abstract = {This commentary examines the Duolingo English Test Responsible AI standards and provides some thoughts on specific ways we can evaluate the use of AI for automated scoring.}
}
@article{doi:10.1177/00368504241275371,
author = {Muzammil Khan and Fahmida Gulan and Muhammad Arshad and Abnash Zaman and Ammara Riaz},
title = {Early and late blight disease identification in tomato plants using a neural network-based model to augmenting agricultural productivity},
journal = {Science Progress},
volume = {107},
number = {3},
pages = {00368504241275371},
year = {2024},
doi = {10.1177/00368504241275371},
note = {PMID:39262392},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00368504241275371},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00368504241275371},
abstract = {Computer-advanced technologies have a significant impact across various fields. It is widely recognized that diseases have a detrimental effect on crop productivity and can significantly impact the economy, particularly in agricultural countries. Tomatoes hold great economic importance among cash crops, second only to potatoes. Globally, tomato production reaches a staggering 160 million tons annually, making it even more crucial for agricultural development. Unfortunately, the tomato crop is susceptible to several diseases, with early blight and late blight as two prominent culprits responsible for a production decrease of around 79%. Traditional disease detection and identification methods are time-consuming, expensive, and destructive, often requiring pathologists’ expertise. Thus, the primary research objective is to enhance disease identification accuracy by leveraging deep learning techniques. A model based on the inception-V3 architecture has been devised to classify diseases affecting tomato plant leaves. The model was trained and tested using the PlantVillage dataset, which comprises 6000 sample images of tomato leaves. The training and testing process utilized an 80 : 20 ratio, resulting in an impressive classification accuracy of 97.44% for the proposed model. The proposed solution aims to enable the tomato industry to thrive in the global market by mitigating the impact of tomato leaf diseases. By reducing the prevalence of these diseases, the solution can increase demand and contribute to the industry’s growth.}
}
@article{doi:10.3102/10769986221115446,
author = {Weicong Lyu and Jee-Seon Kim and Youmi Suk},
title = {Estimating Heterogeneous Treatment Effects Within Latent Class Multilevel Models: A Bayesian Approach},
journal = {Journal of Educational and Behavioral Statistics},
volume = {48},
number = {1},
pages = {3–36},
year = {2023},
doi = {10.3102/10769986221115446},
URL = {https://doi-org.ez.unisabana.edu.co/10.3102/10769986221115446},
eprint = {https://doi-org.ez.unisabana.edu.co/10.3102/10769986221115446},
abstract = {This article presents a latent class model for multilevel data to identify latent subgroups and estimate heterogeneous treatment effects. Unlike sequential approaches that partition data first and then estimate average treatment effects (ATEs) within classes, we employ a Bayesian procedure to jointly estimate mixing probability, selection, and outcome models so that misclassification does not obstruct estimation of treatment effects. Simulation demonstrates that the proposed method finds the correct number of latent classes, estimates class-specific treatment effects well, and provides proper posterior standard deviations and credible intervals of ATEs. We apply this method to Trends in International Mathematics and Science Study data to investigate the effects of private science lessons on achievement scores and then find two latent classes, one with zero ATE and the other with positive ATE.}
}
@article{doi:10.1177/23328584211071112,
author = {Joseph F. T. Nese},
title = {Comparing the Growth and Predictive Performance of a Traditional Oral Reading Fluency Measure With an Experimental Novel Measure},
journal = {AERA Open},
volume = {8},
number = { },
pages = {23328584211071110},
year = {2022},
doi = {10.1177/23328584211071112},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/23328584211071112},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/23328584211071112},
abstract = {Curriculum-based measurement of oral reading fluency (CBM-R) is used as an indicator of reading proficiency, and to measure at risk students’ response to reading interventions to help ensure effective instruction. The purpose of this study was to compare model-based words read correctly per minute (WCPM) scores (computerized oral reading evaluation [CORE]) with Traditional CBM-R WCPM scores to determine which provides more reliable growth estimates and demonstrates better predictive performance of reading comprehension and state reading test scores. Results indicated that in general, CORE had better (a) within-growth properties (smaller SDs of slope estimates and higher reliability), and (b) predictive performance (lower root mean square error, and higher R2, sensitivity, specificity, and area under the curve values). These results suggest increased measurement precision for the model-based CORE scores compared with Traditional CBM-R, providing preliminary evidence that CORE can be used for consequential assessment.}
}
@article{doi:10.1177/1834490921991430,
author = {Päivi Timonen and Heli Ruokamo},
title = {Designing a Preliminary Model of Coaching Pedagogy for Synchronous Collaborative Online Learning},
journal = {Journal of Pacific Rim Psychology},
volume = {15},
number = { },
pages = {1834490921991430},
year = {2021},
doi = {10.1177/1834490921991430},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/1834490921991430},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/1834490921991430},
abstract = {In recent years, webinar platforms have been broadly utilized in online learning where students meet one another synchronously online. This research’s underlying value is its recognition of the utmost importance of the awareness that online learning is a social process, as is all learning. This study aims to find out what kinds of synchronous collaborative online coaching pedagogy models have been used in previous research and proceeds to construct a preliminary pedagogical model for a coaching pedagogy for synchronous collaborative online learning (CPSCOL). The methods comprise a systematic literature review and qualitative-data and theory-driven content analysis. Through the systematic literature review, peer-reviewed articles spanning 2014–2018 are carefully examined. The results identify the following pedagogical framework, theory, and model combinations for synchronous collaborative online learning: the Community of Inquiry framework, including social, cognitive, and teaching presence; social presence in conjunction with the media synchronicity theory or the broaden-and-build theory, or the 4E Learning Cycle (engagement, exploration, explanation, and extension); no specific pedagogy; problem-based learning with Community of Inquiry framework or FISh (focus, investigate, and share); collaborative learning and collaborative learning connected to social presence; Carpe Diem with the Five-Step Model; and coaching pedagogy. The preliminary results indicate a scarcity of research on synchronous coaching pedagogy in online education. Consequently, the CPSCOL model for collaborative online learning, including cognitive, social, and teaching presence, is introduced to formulate a new perspective regarding webinar pedagogy. The process of learners, skills, and competences should factor in the pedagogical methods designed by a coach (teacher), and the results show that webinar pedagogy enables and enhances active collaborative learning and knowledge construction in groups. In addition, 18 CPSCOL principles of practice have been developed to support the practical implementation of the CPSCOL mode.}
}
@article{doi:10.1177/17454999241256447,
author = {Passy Claire Wood and C. Deha Doğan},
title = {A comparative study on assessment methods used by high school teachers in Uganda and Turkey},
journal = {Research in Comparative and International Education},
volume = {19},
number = {3},
pages = {352–370},
year = {2024},
doi = {10.1177/17454999241256447},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/17454999241256447},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/17454999241256447},
abstract = {Assessment and evaluation are crucial to improving educational quality. Examining the opinions of teachers from various countries on in-class assessments can significantly enhance education systems. Similarities and differences in Uganda’s and Turkey’s educational systems justify comparing them. This study aimed to examine and compare the assessment methods used by teachers working in high schools in Uganda and Turkey to determine student achievement. The researcher administered the questionnaire to 119 Ugandan and 85 Turkish high school teachers working in public and private schools in both countries. The researcher used Casual comparative research. The Mann–Whitney U test was used for data analysis. The findings show that Turkish teachers use many in-class assessment methods more often than Ugandan teachers. Compared to Turkish teachers, Ugandan teachers view themselves as more capable of giving student feedback but less competent in taking measures to increase objective scoring. The article outlines further findings and provides recommendations.}
}
@article{doi:10.1177/07356331221137107,
author = {Rushi Yu and Meishu Wang and Jie Hu},
title = {The Relationship Between ICT Perceived Competence and Adolescents’ Digital Reading Performance: A Multilevel Mediation Study},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {4},
pages = {817–846},
year = {2023},
doi = {10.1177/07356331221137107},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221137107},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/07356331221137107},
abstract = {The age of information and communication technology (ICT) has witnessed the prevalence of computer-based reading. Previous studies yielded mixed results concerning the relationship between ICT perceived competence, ICT use and digital reading performance, and the underlying mechanism was rarely explored. This study aimed to explore the relationship between ICT perceived competence and adolescents’ digital reading performance and the potential mediating roles of three types of ICT use. Multilevel mediation analyses were conducted for 199,646 15-year-old students from 29 OECD countries/regions in the Programme for International Student Assessment (PISA) 2018, in which digital reading performance was assessed by multistage adaptive computer-based testing. The results revealed that a) ICT perceived competence and digital reading performance were positively correlated; b) ICT use significantly mediated the relationship; c) students with higher-level ICT perceived competence tended to use ICT for leisure at home more frequently, which led to better digital reading performance; d) the suppression effects were revealed, indicating the need to consider the interrelationship between ICT perceived competence and ICT use. These findings provided new evidence for the self-determination theory and the ICT engagement model, suggesting that appropriate ICT use driven by high-level ICT perceived competence might help improve adolescents’ digital reading performanc.}
}
@article{doi:10.1177/13621688241256436,
title = {Notes on contributors},
journal = {Language Teaching Research},
volume = {28},
number = {4},
pages = {1283–1287},
year = {2024},
doi = {10.1177/13621688241256436},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/13621688241256436},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/13621688241256436}
}
@article{doi:10.1177/0973258621992644,
author = {Ricardo Godinho Bilro and Sandra Maria Correia Loureiro and Fernando José de Aires Angelino},
title = {The Role of Creative Communications and Gamification in Student Engagement in Higher Education: A Sentiment Analysis Approach},
journal = {Journal of Creative Communications},
volume = {17},
number = {1},
pages = {7–21},
year = {2022},
doi = {10.1177/0973258621992644},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/0973258621992644},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/0973258621992644},
abstract = {This article aims to explore gamification tools in services and higher education environments and their role in creating student engagement. The research adopts a qualitative method based on quasi-experimental design. Participants from a higher education institution are exposed to gamification activities during a full semester. Researchers use the sentiment analysis (SA) technique based on a text-mining approach to analyse the data. Findings reveal that participants perceive gamification in service settings as a useful tool. The global SA reveals a positive sentiment about the gamification approach that contributes to increasing participants’ engagement. This study’s novelty arises from quasi-experimental research to measure gamification activities’ impact on students’ engagement, measured through SA of their opinions.}
}
@article{doi:10.1177/09726225231173054,
author = {A. K. Konar and Ayesha Martin and Sombala Ningthoujam},
title = {Validating an Automated System of Evaluation for English Drafting Skill: A Case of Large-scale, High-stakes Selection of Entry-level Managerial Positions},
journal = {Metamorphosis},
volume = {22},
number = {1},
pages = {18–27},
year = {2023},
doi = {10.1177/09726225231173054},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/09726225231173054},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/09726225231173054},
abstract = {The effectiveness of using a constructed response measure for assessing drafting ability is proven and has been used extensively in managerial selection in state-owned organizations. With the advent of online recruitment trends and technology-enhanced assessments, automated scoring has been conceived as a replacement for human scoring with the purpose of emulating the human scoring system. In the context of large-scale writing assessments, automated scoring could provide superior results to human scoring in terms of validity and reliability. In the present study, an attempt has been made to validate an automated essay scoring (AES) algorithm. The study was conducted on a sample of 11,497 randomly selected from a population of 54,392 shortlisted candidates for a national-level examination for the selection of entry-level executives in managerial positions in state-owned banks and a state-owned insurance company. The evaluation of the descriptive (constructed response) component of the examination (English composition) was carried out parallelly by four expert human raters and the AES algorithm. The parameters for evaluation were devised and made available to raters and the algorithm. Data were analysed using mean SD and Pearson correlation coefficient. Results show that the mean scores of human expert raters (M = 14.648) and automated algorithm method (M = 15.804) were similar. Further analysis was also undertaken to check the convergent validity of the features used in the algorithm by examining the relation of algorithm scores with sub scores from the objective test of the same construct. Results indicate a significant correlation. It can thus be said that the algorithm scoring method developed can be considered a replacement in that it can complement human expert raters in the evaluation of descriptive papers with consistent scoring and fairness, without inherent biases of inter-rater and intra-rater variation, in addition to practical benefits of speed and cost.}
}
@article{doi:10.1177/00169862221124887,
author = {Scott J. Peters and Tamra Stambaugh and Matthew C. Makel and Lindsay Ellis Lee and Matthew T. McBee and D. Betsy McCoach and Kiana R. Johnson},
title = {The CASA Criteria for Evaluating Gifted and Talented Identification Systems: Cost, Alignment, Sensitivity, and Access},
journal = {Gifted Child Quarterly},
volume = {67},
number = {2},
pages = {137–150},
year = {2023},
doi = {10.1177/00169862221124887},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/00169862221124887},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/00169862221124887},
abstract = {Debates over identification procedures for gifted and talented students dominate the field and serve as the topic of many of its internal and external debates. We believe this is due to a lack of commonly accepted criteria for how to evaluate identification procedures. In this article, we present the Cost, Alignment, Sensitivity, and Access (CASA) criteria, a framework to evaluate identification systems according to their cost, alignment to services, sensitivity, and access. We believe these criteria would facilitate more productive conversations over identification and continued growth and improvement for the field as a whole.}
}
@article{doi:10.1080/02109395.2020.1748842,
author = {María I. Susperreguy and Christian Peake and David M. Gómez},
title = {Research on numerical cognition in Chile: current status, links to education and challenges (Investigación en cognición numérica en Chile: estado actual, vínculos con la educación y desafíos)},
journal = {Studies in Psychology},
volume = {41},
number = {2},
pages = {404–438},
year = {2020},
doi = {10.1080/02109395.2020.1748842},
URL = {https://doi-org.ez.unisabana.edu.co/10.1080/02109395.2020.1748842},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1080/02109395.2020.1748842},
abstract = {Research on numerical cognition, an emerging area that has received increasing interest in Chile, can contribute to understanding how mathematical skills are developed and support education. This article reviews the studies published in the field of numerical cognition in Chile, indexed in the WoS, PubMed, Scopus and SciELO databases. The articles reviewed address mechanisms that underlie mathematical performance and strategies used by children, adolescents and adults to solve mathematical tasks, with a special emphasis on early skills, calculations and arithmetic, as well as factors associated with individual differences in the development of mathematical notions. This article also analyses the sources of funding that support research on numerical cognition and education in Chile and the projects awarded such funds in recent years. Finally, the contribution and challenges of numerical cognition research in Chile in an educational context are discusse.}
}
@article{doi:10.1177/21582440241262864,
author = {Jiseung Yoo and Jisun Park and Minsu Ha and Chelcea Mae Lagmay Darang},
title = {Exploring Pre-Service Teachers’ Cognitive Processes and Calibration with an Unsupervised Learning-Based Automated Evaluation System},
journal = {Sage Open},
volume = {14},
number = {3},
pages = {21582440241262864},
year = {2024},
doi = {10.1177/21582440241262864},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/21582440241262864},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/21582440241262864},
abstract = {In the context of formative assessment in classrooms, the incorporation of automated evaluation (AE) systems and teachers’ interactions with them hold significant importance. This study aimed to investigate the cognitive processes of pre-service teachers as they engaged with an AE system. We developed an unsupervised learning-based AE system, the Scoring Assistant using Artificial Intelligence (SAAI). SAAI calculates scores without relying on predefined labels and generates scientific keywords from student responses to provide constructive feedback. We collected a substantial number of constructed responses from students, and four pre-service teachers evaluated these responses initially without any external assistance and then re-evaluated them using SAAI scores as a reference point. Employing a mixed-methods approach, this study demonstrated a strong level of consistency between human raters and SAAI scores. Pre-service teachers also reflectively recalibrated their assessments and adjusted their rubrics to identify students’ learning more accurately. This study highlights the practical application of AE in real classroom settings and demonstrates how AE can enhance efficiency and accuracy in K-12 science assessments, thus supporting teachers.}
}
@article{doi:10.1177/21925682211047969,
title = {E-Posters},
journal = {Global Spine Journal},
volume = {11},
number = {2_suppl},
pages = {214S-561S},
year = {2021},
doi = {10.1177/21925682211047969},
note = {PMID:34698577},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/21925682211047969},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/21925682211047969}
}
@article{doi:10.1177/23969873241245672,
title = {10th European Stroke Organisation Conference Abstracts – 15-17 May 2024, Basel, Switzerland},
journal = {European Stroke Journal},
volume = {9},
number = {1_suppl},
pages = {3–647},
year = {2024},
doi = {10.1177/23969873241245672},
URL = {https://doi-org.ez.unisabana.edu.co/10.1177/23969873241245672},
eprint = {https://doi-org.ez.unisabana.edu.co/10.1177/23969873241245672}
}
